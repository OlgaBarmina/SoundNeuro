{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UdsrHlDFR8EB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEERbDXjSmCh",
    "outputId": "a6ed1555-8301-45fa-b01a-082036833e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 30000\n"
     ]
    }
   ],
   "source": [
    "ds_dir = '/arch/mnist_data'\n",
    "filenames = []\n",
    "\n",
    "for root, dirs, files in os.walk(ds_dir):\n",
    "    for file in files:\n",
    "        filenames.append(os.path.join(root,file))\n",
    "filenames = [re.sub(r'(\\\\)', '/', name) for name in filenames[1:]]\n",
    "\n",
    "samples_number = len(filenames)\n",
    "print('Total number of samples:', samples_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbE_0KGkS4xo",
    "outputId": "aacae527-a942-4555-90dd-e9c2b3e6efe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size 21000\n",
      "Test data size 6030\n",
      "Validation data size 2970\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "train_files,test_files = train_test_split(filenames, test_size=0.3, shuffle=True, random_state=1)\n",
    "test_files,val_files = train_test_split(test_files, test_size=0.33, shuffle=True, random_state=1)\n",
    "\n",
    "print('Training data size', len(train_files))\n",
    "print('Test data size', len(test_files))\n",
    "print('Validation data size', len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_24GUB7FeV16"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    label = re.findall(r'/([0-9])_', file_path)[0]\n",
    "    index = np.argmax(label == labels)\n",
    "    label_id = np.zeros(len(labels), dtype=np.float64)\n",
    "    label_id[index] = 1\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ct0Q8zUlfj4w"
   },
   "outputs": [],
   "source": [
    "def get_ms(file_path, input_shape):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    ms = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=512)\n",
    "    ms = np.resize(ms, input_shape)\n",
    "    ms = ms.astype(np.float64, copy=False)\n",
    "    \n",
    "    ms = np.log(ms + 1e-9)\n",
    "    ms = librosa.util.normalize(ms)\n",
    "    \n",
    "    ms = np.repeat(ms[..., np.newaxis], 3, -1)\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4LmQusI6cFUm"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(files, input_shape):\n",
    "    output_labels = np.array([get_label(file) for file in files])\n",
    "    output_ms = np.array([get_ms(file, input_shape) for file in files])\n",
    "    return output_ms, output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epoch=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uQBzV_u_j3As",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (128,44)\n",
    "train_ms,train_labels = preprocess_dataset(train_files, input_shape)\n",
    "test_ms,test_labels = preprocess_dataset(test_files, input_shape)\n",
    "val_ms,val_labels = preprocess_dataset(val_files, input_shape)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_ms, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_ms, test_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_ms, val_labels))\n",
    "\n",
    "train_batches = train_dataset.batch(batch_size)\n",
    "test_batches = test_dataset.batch(batch_size)\n",
    "val_batches = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def metric_calc(model):\n",
    "    y_true=test_labels\n",
    "    y_pred = model.predict(test_batches, verbose=2)\n",
    "    \n",
    "    y_pred = np.array([np.argmax(i) for i in y_pred])   \n",
    "    y_true = np.array([np.argmax(i) for i in y_true])\n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = sklearn.metrics.precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = sklearn.metrics.recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 1051s 3s/step - loss: 0.5687 - accuracy: 0.8004 - f1_score: 0.3824 - precision: 0.2388 - recall: 0.9633 - val_loss: 0.5168 - val_accuracy: 0.8148 - val_f1_score: 0.4043 - val_precision: 0.2539 - val_recall: 0.9924\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 995s 3s/step - loss: 0.1552 - accuracy: 0.9479 - f1_score: 0.4145 - precision: 0.2616 - recall: 0.9990 - val_loss: 0.3075 - val_accuracy: 0.8993 - val_f1_score: 0.4153 - val_precision: 0.2622 - val_recall: 0.9983\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 958s 3s/step - loss: 0.0700 - accuracy: 0.9776 - f1_score: 0.4259 - precision: 0.2707 - recall: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9242 - val_f1_score: 0.4177 - val_precision: 0.2641 - val_recall: 0.9993\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 958s 3s/step - loss: 0.0300 - accuracy: 0.9925 - f1_score: 0.4325 - precision: 0.2760 - recall: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9707 - val_f1_score: 0.4340 - val_precision: 0.2773 - val_recall: 0.9993\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 959s 3s/step - loss: 0.0129 - accuracy: 0.9981 - f1_score: 0.4370 - precision: 0.2796 - recall: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9747 - val_f1_score: 0.4377 - val_precision: 0.2803 - val_recall: 0.9990\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 957s 3s/step - loss: 0.0061 - accuracy: 0.9992 - f1_score: 0.4391 - precision: 0.2814 - recall: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9764 - val_f1_score: 0.4413 - val_precision: 0.2832 - val_recall: 0.9990\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 957s 3s/step - loss: 0.0027 - accuracy: 1.0000 - f1_score: 0.4407 - precision: 0.2827 - recall: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9818 - val_f1_score: 0.4423 - val_precision: 0.2840 - val_recall: 0.9993\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 959s 3s/step - loss: 0.0016 - accuracy: 1.0000 - f1_score: 0.4420 - precision: 0.2837 - recall: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9818 - val_f1_score: 0.4455 - val_precision: 0.2867 - val_recall: 0.9990\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 955s 3s/step - loss: 0.0013 - accuracy: 1.0000 - f1_score: 0.4430 - precision: 0.2846 - recall: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9825 - val_f1_score: 0.4475 - val_precision: 0.2884 - val_recall: 0.9990\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 955s 3s/step - loss: 0.0011 - accuracy: 1.0000 - f1_score: 0.4439 - precision: 0.2853 - recall: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9828 - val_f1_score: 0.4488 - val_precision: 0.2895 - val_recall: 0.9990\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 956s 3s/step - loss: 9.9263e-04 - accuracy: 1.0000 - f1_score: 0.4447 - precision: 0.2860 - recall: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9835 - val_f1_score: 0.4492 - val_precision: 0.2898 - val_recall: 0.9990\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 956s 3s/step - loss: 8.9850e-04 - accuracy: 1.0000 - f1_score: 0.4454 - precision: 0.2865 - recall: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9835 - val_f1_score: 0.4499 - val_precision: 0.2904 - val_recall: 0.9990\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 954s 3s/step - loss: 8.2558e-04 - accuracy: 1.0000 - f1_score: 0.4461 - precision: 0.2871 - recall: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9835 - val_f1_score: 0.4501 - val_precision: 0.2906 - val_recall: 0.9990\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 955s 3s/step - loss: 7.6722e-04 - accuracy: 1.0000 - f1_score: 0.4466 - precision: 0.2876 - recall: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9835 - val_f1_score: 0.4505 - val_precision: 0.2909 - val_recall: 0.9990\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 955s 3s/step - loss: 7.1936e-04 - accuracy: 1.0000 - f1_score: 0.4470 - precision: 0.2879 - recall: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9835 - val_f1_score: 0.4510 - val_precision: 0.2913 - val_recall: 0.9990\n"
     ]
    }
   ],
   "source": [
    "model_densenet121 = tf.keras.applications.densenet.DenseNet121(input_shape=input_shape+(3,), include_top=False, weights=None)\n",
    "\n",
    "densenet121 = keras.Sequential([\n",
    "    model_densenet121,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))               \n",
    "])\n",
    "\n",
    "densenet121.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_densenet121 = densenet121.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 69s - 69s/epoch - 729ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.982089552238806, 0.9821046468661228, 0.982089552238806, 0.9820814800019442)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(densenet121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 67s - loss: 0.0659 - accuracy: 0.9821 - f1_score: 0.4508 - precision: 0.2911 - recall: 0.9998 - 67s/epoch - 700ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = densenet121.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/densenet121_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/densenet121_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "densenet121.save(\"models/densenet121_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 1433s 4s/step - loss: 0.5926 - accuracy: 0.7916 - f1_score: 0.4102 - precision: 0.2629 - recall: 0.9493 - val_loss: 0.9252 - val_accuracy: 0.6936 - val_f1_score: 0.4097 - val_precision: 0.2608 - val_recall: 0.9555\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 1409s 4s/step - loss: 0.1716 - accuracy: 0.9397 - f1_score: 0.4381 - precision: 0.2807 - recall: 0.9988 - val_loss: 0.3054 - val_accuracy: 0.8983 - val_f1_score: 0.4469 - val_precision: 0.2882 - val_recall: 0.9957\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 1395s 4s/step - loss: 0.0716 - accuracy: 0.9760 - f1_score: 0.4495 - precision: 0.2900 - recall: 0.9999 - val_loss: 0.1261 - val_accuracy: 0.9572 - val_f1_score: 0.4503 - val_precision: 0.2907 - val_recall: 0.9990\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 1394s 4s/step - loss: 0.0280 - accuracy: 0.9926 - f1_score: 0.4552 - precision: 0.2948 - recall: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9704 - val_f1_score: 0.4628 - val_precision: 0.3012 - val_recall: 0.9990\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 1404s 4s/step - loss: 0.0111 - accuracy: 0.9977 - f1_score: 0.4603 - precision: 0.2990 - recall: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9761 - val_f1_score: 0.4602 - val_precision: 0.2990 - val_recall: 0.9990\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 1390s 4s/step - loss: 0.0041 - accuracy: 0.9998 - f1_score: 0.4624 - precision: 0.3008 - recall: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9815 - val_f1_score: 0.4671 - val_precision: 0.3049 - val_recall: 0.9990\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 1379s 4s/step - loss: 0.0019 - accuracy: 1.0000 - f1_score: 0.4643 - precision: 0.3024 - recall: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9832 - val_f1_score: 0.4698 - val_precision: 0.3072 - val_recall: 0.9993\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 1385s 4s/step - loss: 0.0013 - accuracy: 1.0000 - f1_score: 0.4659 - precision: 0.3038 - recall: 1.0000 - val_loss: 0.0618 - val_accuracy: 0.9822 - val_f1_score: 0.4700 - val_precision: 0.3073 - val_recall: 0.9993\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 1394s 4s/step - loss: 0.0010 - accuracy: 1.0000 - f1_score: 0.4671 - precision: 0.3048 - recall: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9815 - val_f1_score: 0.4714 - val_precision: 0.3085 - val_recall: 0.9993\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 1386s 4s/step - loss: 8.9057e-04 - accuracy: 1.0000 - f1_score: 0.4681 - precision: 0.3056 - recall: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9815 - val_f1_score: 0.4722 - val_precision: 0.3092 - val_recall: 0.9993\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 1380s 4s/step - loss: 7.9361e-04 - accuracy: 1.0000 - f1_score: 0.4689 - precision: 0.3063 - recall: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9815 - val_f1_score: 0.4735 - val_precision: 0.3103 - val_recall: 0.9993\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 1393s 4s/step - loss: 7.2139e-04 - accuracy: 1.0000 - f1_score: 0.4693 - precision: 0.3067 - recall: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9815 - val_f1_score: 0.4743 - val_precision: 0.3110 - val_recall: 0.9993\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 1384s 4s/step - loss: 6.6522e-04 - accuracy: 1.0000 - f1_score: 0.4699 - precision: 0.3072 - recall: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9815 - val_f1_score: 0.4747 - val_precision: 0.3114 - val_recall: 0.9993\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 1384s 4s/step - loss: 6.1998e-04 - accuracy: 1.0000 - f1_score: 0.4704 - precision: 0.3076 - recall: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9815 - val_f1_score: 0.4753 - val_precision: 0.3119 - val_recall: 0.9993\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 1398s 4s/step - loss: 5.8259e-04 - accuracy: 1.0000 - f1_score: 0.4708 - precision: 0.3080 - recall: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9815 - val_f1_score: 0.4756 - val_precision: 0.3121 - val_recall: 0.9993\n"
     ]
    }
   ],
   "source": [
    "model_densenet169 = tf.keras.applications.densenet.DenseNet169(input_shape=input_shape+(3,), include_top=False, weights=None)\n",
    "\n",
    "densenet169 = keras.Sequential([\n",
    "    model_densenet169,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                  \n",
    "])\n",
    "\n",
    "densenet169.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_densenet169 = densenet169.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 102s - 102s/epoch - 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9817578772802653,\n",
       " 0.9817573768670986,\n",
       " 0.9817578772802653,\n",
       " 0.9817387830120752)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(densenet169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 101s - loss: 0.0660 - accuracy: 0.9818 - f1_score: 0.4737 - precision: 0.3105 - recall: 0.9995 - 101s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = densenet169.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 168). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/densenet169_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/densenet169_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "densenet169.save(\"models/densenet169_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 1806s 5s/step - loss: 0.5938 - accuracy: 0.7896 - f1_score: 0.3877 - precision: 0.2432 - recall: 0.9612 - val_loss: 0.7015 - val_accuracy: 0.7609 - val_f1_score: 0.4002 - val_precision: 0.2512 - val_recall: 0.9834\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 1781s 5s/step - loss: 0.1641 - accuracy: 0.9401 - f1_score: 0.4146 - precision: 0.2616 - recall: 0.9990 - val_loss: 0.2024 - val_accuracy: 0.9343 - val_f1_score: 0.4187 - val_precision: 0.2649 - val_recall: 0.9987\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 1776s 5s/step - loss: 0.0701 - accuracy: 0.9763 - f1_score: 0.4250 - precision: 0.2699 - recall: 0.9999 - val_loss: 0.2538 - val_accuracy: 0.9266 - val_f1_score: 0.4112 - val_precision: 0.2590 - val_recall: 0.9983\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 1779s 5s/step - loss: 0.0325 - accuracy: 0.9907 - f1_score: 0.4325 - precision: 0.2760 - recall: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9525 - val_f1_score: 0.4232 - val_precision: 0.2686 - val_recall: 0.9987\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 1777s 5s/step - loss: 0.0138 - accuracy: 0.9967 - f1_score: 0.4363 - precision: 0.2791 - recall: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9667 - val_f1_score: 0.4325 - val_precision: 0.2760 - val_recall: 0.9997\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 1780s 5s/step - loss: 0.0047 - accuracy: 0.9997 - f1_score: 0.4380 - precision: 0.2805 - recall: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9818 - val_f1_score: 0.4398 - val_precision: 0.2820 - val_recall: 0.9993\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 1786s 5s/step - loss: 0.0019 - accuracy: 1.0000 - f1_score: 0.4399 - precision: 0.2820 - recall: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9811 - val_f1_score: 0.4438 - val_precision: 0.2853 - val_recall: 0.9993\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 1787s 5s/step - loss: 0.0012 - accuracy: 1.0000 - f1_score: 0.4409 - precision: 0.2828 - recall: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9825 - val_f1_score: 0.4445 - val_precision: 0.2858 - val_recall: 0.9993\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 1812s 6s/step - loss: 9.9314e-04 - accuracy: 1.0000 - f1_score: 0.4418 - precision: 0.2836 - recall: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9822 - val_f1_score: 0.4456 - val_precision: 0.2867 - val_recall: 0.9993\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 1790s 5s/step - loss: 8.5844e-04 - accuracy: 1.0000 - f1_score: 0.4427 - precision: 0.2843 - recall: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9825 - val_f1_score: 0.4467 - val_precision: 0.2877 - val_recall: 0.9993\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 1787s 5s/step - loss: 7.6529e-04 - accuracy: 1.0000 - f1_score: 0.4435 - precision: 0.2850 - recall: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9828 - val_f1_score: 0.4474 - val_precision: 0.2882 - val_recall: 0.9993\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 1795s 5s/step - loss: 6.9579e-04 - accuracy: 1.0000 - f1_score: 0.4440 - precision: 0.2854 - recall: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9828 - val_f1_score: 0.4480 - val_precision: 0.2888 - val_recall: 0.9993\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 1795s 5s/step - loss: 6.4170e-04 - accuracy: 1.0000 - f1_score: 0.4445 - precision: 0.2859 - recall: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9832 - val_f1_score: 0.4482 - val_precision: 0.2890 - val_recall: 0.9993\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 1794s 5s/step - loss: 5.9822e-04 - accuracy: 1.0000 - f1_score: 0.4449 - precision: 0.2862 - recall: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9832 - val_f1_score: 0.4489 - val_precision: 0.2895 - val_recall: 0.9993\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 1783s 5s/step - loss: 5.6229e-04 - accuracy: 1.0000 - f1_score: 0.4452 - precision: 0.2864 - recall: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9832 - val_f1_score: 0.4490 - val_precision: 0.2896 - val_recall: 0.9993\n"
     ]
    }
   ],
   "source": [
    "model_densenet201 = tf.keras.applications.densenet.DenseNet201(input_shape=input_shape+(3,), include_top=False, weights=None)\n",
    "\n",
    "densenet201 = keras.Sequential([\n",
    "    model_densenet201,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                  \n",
    "])\n",
    "\n",
    "densenet201.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_densenet201 = densenet201.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 147s - 147s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.982089552238806, 0.9820771970363731, 0.982089552238806, 0.9820772018039268)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(densenet201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 147s - loss: 0.0638 - accuracy: 0.9821 - f1_score: 0.4491 - precision: 0.2896 - recall: 0.9998 - 147s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = densenet201.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 200). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/densenet201_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/densenet201_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "densenet201.save(\"models/densenet201_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShuffleNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code: https://github.com/opconty/keras-shufflenetV2/blob/master/shufflenetv2.py\n",
    "import keras_applications\n",
    "import keras.backend as K\n",
    "\n",
    "def channel_split(x, name=''):\n",
    "    # equipartition\n",
    "    in_channles = x.shape.as_list()[-1]\n",
    "    ip = in_channles // 2\n",
    "    c_hat = keras.layers.Lambda(lambda z: z[:, :, :, 0:ip], name='%s/sp%d_slice' % (name, 0))(x)\n",
    "    c = keras.layers.Lambda(lambda z: z[:, :, :, ip:], name='%s/sp%d_slice' % (name, 1))(x)\n",
    "    return c_hat, c\n",
    "\n",
    "def channel_shuffle(x):\n",
    "    height, width, channels = x.shape.as_list()[1:]\n",
    "    channels_per_split = channels // 2\n",
    "    x = K.reshape(x, [-1, height, width, 2, channels_per_split])\n",
    "    x = K.permute_dimensions(x, (0,1,2,4,3))\n",
    "    x = K.reshape(x, [-1, height, width, channels])\n",
    "    return x\n",
    "\n",
    "def shuffle_unit(inputs, out_channels, bottleneck_ratio,strides=2,stage=1,block=1):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = -1\n",
    "    else:\n",
    "        raise ValueError('Only channels last supported')\n",
    "\n",
    "    prefix = 'stage{}/block{}'.format(stage, block)\n",
    "    bottleneck_channels = int(out_channels * bottleneck_ratio)\n",
    "    if strides < 2:\n",
    "        c_hat, c = channel_split(inputs, '{}/spl'.format(prefix))\n",
    "        inputs = c\n",
    "\n",
    "    x = keras.layers.Conv2D(bottleneck_channels, kernel_size=(1,1), strides=1, padding='same', \n",
    "                            name='{}/1x1conv_1'.format(prefix))(inputs)\n",
    "    x = keras.layers.BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_1'.format(prefix))(x)\n",
    "    x = keras.layers.Activation('relu', name='{}/relu_1x1conv_1'.format(prefix))(x)\n",
    "    x = keras.layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', name='{}/3x3dwconv'.format(prefix))(x)\n",
    "    x = keras.layers.BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv'.format(prefix))(x)\n",
    "    x = keras.layers.Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', name='{}/1x1conv_2'.format(prefix))(x)\n",
    "    x = keras.layers.BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_2'.format(prefix))(x)\n",
    "    x = keras.layers.Activation('relu', name='{}/relu_1x1conv_2'.format(prefix))(x)\n",
    "    \n",
    "    if strides < 2:\n",
    "        ret = keras.layers.Concatenate(axis=bn_axis, name='{}/concat_1'.format(prefix))([x, c_hat])\n",
    "    else:\n",
    "        s2 = keras.layers.DepthwiseConv2D(kernel_size=3, strides=2, padding='same', \n",
    "                                name='{}/3x3dwconv_2'.format(prefix))(inputs)\n",
    "        s2 = keras.layers.BatchNormalization(axis=bn_axis, name='{}/bn_3x3dwconv_2'.format(prefix))(s2)\n",
    "        s2 = keras.layers.Conv2D(bottleneck_channels, kernel_size=1,strides=1,padding='same', \n",
    "                                 name='{}/1x1_conv_3'.format(prefix))(s2)\n",
    "        s2 = keras.layers.BatchNormalization(axis=bn_axis, name='{}/bn_1x1conv_3'.format(prefix))(s2)\n",
    "        s2 = keras.layers.Activation('relu', name='{}/relu_1x1conv_3'.format(prefix))(s2)\n",
    "        ret = keras.layers.Concatenate(axis=bn_axis, name='{}/concat_2'.format(prefix))([x, s2])\n",
    "\n",
    "    ret = keras.layers.Lambda(channel_shuffle, name='{}/channel_shuffle'.format(prefix))(ret)\n",
    "\n",
    "    return ret\n",
    "\n",
    "def block(x, channel_map, bottleneck_ratio, repeat=1, stage=1):\n",
    "    x = shuffle_unit(x, out_channels=channel_map[stage-1],\n",
    "                      strides=2,bottleneck_ratio=bottleneck_ratio,stage=stage,block=1)\n",
    "\n",
    "    for i in range(1, repeat+1):\n",
    "        x = shuffle_unit(x, out_channels=channel_map[stage-1],strides=1,\n",
    "                          bottleneck_ratio=bottleneck_ratio,stage=stage, block=(1+i))\n",
    "\n",
    "    return x\n",
    "\n",
    "def ShuffleNetV2(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 scale_factor=1.0,\n",
    "                 pooling='max',\n",
    "                 input_shape=(3,128,44),\n",
    "                 load_model=None,\n",
    "                 num_shuffle_units=[3,7,3],\n",
    "                 bottleneck_ratio=1,\n",
    "                 classes=len(labels)):\n",
    "    name = 'ShuffleNetV2_{}_{}_{}'.format(scale_factor, bottleneck_ratio, \"\".join([str(x) for x in num_shuffle_units]))\n",
    "    input_shape = keras_applications.imagenet_utils._obtain_input_shape(input_shape, default_size=224, \n",
    "                                    min_size=28, require_flatten=include_top, data_format=K.image_data_format())\n",
    "    out_dim_stage_two = {0.5:48, 1:116, 1.5:176, 2:244}\n",
    "\n",
    "    if pooling not in ['max', 'avg']:\n",
    "        raise ValueError('Invalid value for pooling')\n",
    "    if not (float(scale_factor)*4).is_integer():\n",
    "        raise ValueError('Invalid value for scale_factor, should be x over 4')\n",
    "    exp = np.insert(np.arange(len(num_shuffle_units), dtype=np.float32), 0, 0)  # [0., 0., 1., 2.]\n",
    "    out_channels_in_stage = 2**exp\n",
    "    out_channels_in_stage *= out_dim_stage_two[bottleneck_ratio]  #  calculate output channels for each stage\n",
    "    out_channels_in_stage[0] = 24  # first stage has always 24 output channels\n",
    "    out_channels_in_stage *= scale_factor\n",
    "    out_channels_in_stage = out_channels_in_stage.astype(int)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = keras.layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = keras.layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # create shufflenet architecture\n",
    "    x = keras.layers.Conv2D(filters=out_channels_in_stage[0], kernel_size=(3, 3), padding='same', \n",
    "                            use_bias=False, strides=(2, 2), activation='relu', name='conv1')(img_input)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='maxpool1')(x)\n",
    "\n",
    "    # create stages containing shufflenet units beginning at stage 2\n",
    "    for stage in range(len(num_shuffle_units)):\n",
    "        repeat = num_shuffle_units[stage]\n",
    "        x = block(x, out_channels_in_stage,\n",
    "                   repeat=repeat,\n",
    "                   bottleneck_ratio=bottleneck_ratio,\n",
    "                   stage=stage + 2)\n",
    "\n",
    "    if bottleneck_ratio < 2:\n",
    "        k = 1024\n",
    "    else:\n",
    "        k = 2048\n",
    "    x = keras.layers.Conv2D(k, kernel_size=1, padding='same', strides=1, name='1x1conv5_out', activation='relu')(x)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = keras.layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = keras.layers.GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = keras.layers.Dense(classes, name='fc')(x)\n",
    "        x = keras.layers.Activation('softmax', name='softmax')(x)\n",
    "        \n",
    "    if input_tensor:\n",
    "        inputs = keras.utils.get_source_inputs(input_tensor)\n",
    "\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = keras.models.Model(inputs, x, name=name)\n",
    "\n",
    "    if load_model:\n",
    "        model.load_weights('', by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 464s 1s/step - loss: 1.6206 - accuracy: 0.4271 - f1_score: 0.2868 - precision: 0.6005 - recall: 0.2135 - val_loss: 2.4042 - val_accuracy: 0.0980 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 442s 1s/step - loss: 0.5769 - accuracy: 0.8035 - f1_score: 0.7929 - precision: 0.8710 - recall: 0.7306 - val_loss: 3.3797 - val_accuracy: 0.1185 - val_f1_score: 0.1250 - val_precision: 0.1473 - val_recall: 0.1088\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 444s 1s/step - loss: 0.3286 - accuracy: 0.8912 - f1_score: 0.8890 - precision: 0.9178 - recall: 0.8624 - val_loss: 0.3327 - val_accuracy: 0.8845 - val_f1_score: 0.8902 - val_precision: 0.9142 - val_recall: 0.8679\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 444s 1s/step - loss: 0.1994 - accuracy: 0.9368 - f1_score: 0.9369 - precision: 0.9518 - recall: 0.9226 - val_loss: 0.3535 - val_accuracy: 0.8704 - val_f1_score: 0.8730 - val_precision: 0.8968 - val_recall: 0.8508\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 445s 1s/step - loss: 0.1193 - accuracy: 0.9667 - f1_score: 0.9660 - precision: 0.9740 - recall: 0.9583 - val_loss: 0.2929 - val_accuracy: 0.8956 - val_f1_score: 0.8983 - val_precision: 0.9126 - val_recall: 0.8845\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 446s 1s/step - loss: 0.0732 - accuracy: 0.9829 - f1_score: 0.9819 - precision: 0.9867 - recall: 0.9772 - val_loss: 0.2035 - val_accuracy: 0.9306 - val_f1_score: 0.9314 - val_precision: 0.9397 - val_recall: 0.9234\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 442s 1s/step - loss: 0.0541 - accuracy: 0.9896 - f1_score: 0.9882 - precision: 0.9910 - recall: 0.9856 - val_loss: 0.1911 - val_accuracy: 0.9333 - val_f1_score: 0.9348 - val_precision: 0.9430 - val_recall: 0.9269\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 441s 1s/step - loss: 0.0391 - accuracy: 0.9936 - f1_score: 0.9930 - precision: 0.9948 - recall: 0.9913 - val_loss: 0.1945 - val_accuracy: 0.9360 - val_f1_score: 0.9349 - val_precision: 0.9424 - val_recall: 0.9276\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 441s 1s/step - loss: 0.0260 - accuracy: 0.9967 - f1_score: 0.9967 - precision: 0.9973 - recall: 0.9962 - val_loss: 0.1747 - val_accuracy: 0.9421 - val_f1_score: 0.9417 - val_precision: 0.9473 - val_recall: 0.9362\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 441s 1s/step - loss: 0.0202 - accuracy: 0.9980 - f1_score: 0.9972 - precision: 0.9976 - recall: 0.9969 - val_loss: 0.1739 - val_accuracy: 0.9411 - val_f1_score: 0.9436 - val_precision: 0.9516 - val_recall: 0.9359\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 440s 1s/step - loss: 0.0202 - accuracy: 0.9976 - f1_score: 0.9974 - precision: 0.9980 - recall: 0.9969 - val_loss: 0.1721 - val_accuracy: 0.9441 - val_f1_score: 0.9453 - val_precision: 0.9518 - val_recall: 0.9390\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 442s 1s/step - loss: 0.0142 - accuracy: 0.9989 - f1_score: 0.9988 - precision: 0.9990 - recall: 0.9986 - val_loss: 0.1668 - val_accuracy: 0.9458 - val_f1_score: 0.9451 - val_precision: 0.9500 - val_recall: 0.9402\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 442s 1s/step - loss: 0.0136 - accuracy: 0.9990 - f1_score: 0.9989 - precision: 0.9991 - recall: 0.9986 - val_loss: 0.1647 - val_accuracy: 0.9492 - val_f1_score: 0.9510 - val_precision: 0.9580 - val_recall: 0.9442\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 442s 1s/step - loss: 0.0105 - accuracy: 0.9996 - f1_score: 0.9996 - precision: 0.9998 - recall: 0.9994 - val_loss: 0.1620 - val_accuracy: 0.9485 - val_f1_score: 0.9485 - val_precision: 0.9540 - val_recall: 0.9432\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 442s 1s/step - loss: 0.0094 - accuracy: 0.9996 - f1_score: 0.9992 - precision: 0.9996 - recall: 0.9989 - val_loss: 0.1581 - val_accuracy: 0.9498 - val_f1_score: 0.9516 - val_precision: 0.9566 - val_recall: 0.9467\n"
     ]
    }
   ],
   "source": [
    "shufflenetv2 = ShuffleNetV2(include_top=True, input_shape=input_shape+(3,), load_model=None, classes=len(labels))\n",
    "\n",
    "shufflenetv2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_shufflenetv2 = shufflenetv2.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 33s - loss: 0.1694 - accuracy: 0.9478 - f1_score: 0.9478 - precision: 0.9519 - recall: 0.9439 - 33s/epoch - 352ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = shufflenetv2.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/shufflenetv2_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/shufflenetv2_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "shufflenetv2.save(\"models/shufflenetv2_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapeIR = (128,75)\n",
    "\n",
    "train_msIR,train_labelsIR = preprocess_dataset(train_files, input_shapeIR)\n",
    "test_msIR,test_labelsIR = preprocess_dataset(test_files, input_shapeIR)\n",
    "val_msIR,val_labelsIR = preprocess_dataset(val_files, input_shapeIR)\n",
    "\n",
    "train_datasetIR = tf.data.Dataset.from_tensor_slices((train_msIR, train_labelsIR))\n",
    "test_datasetIR = tf.data.Dataset.from_tensor_slices((test_msIR, test_labelsIR))\n",
    "val_datasetIR = tf.data.Dataset.from_tensor_slices((val_msIR, val_labelsIR))\n",
    "\n",
    "train_batchesIR = train_datasetIR.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "test_batchesIR = test_datasetIR.batch(batch_size)\n",
    "val_batchesIR = val_datasetIR.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 4517s 14s/step - loss: 0.8066 - accuracy: 0.7274 - f1_score: 0.3704 - precision: 0.2315 - recall: 0.9301 - val_loss: 6.3767 - val_accuracy: 0.1428 - val_f1_score: 0.2055 - val_precision: 0.1264 - val_recall: 0.5484\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 4372s 13s/step - loss: 0.2183 - accuracy: 0.9336 - f1_score: 0.4047 - precision: 0.2539 - recall: 0.9981 - val_loss: 0.2758 - val_accuracy: 0.9091 - val_f1_score: 0.4040 - val_precision: 0.2533 - val_recall: 0.9973\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 4368s 13s/step - loss: 0.1153 - accuracy: 0.9710 - f1_score: 0.4112 - precision: 0.2589 - recall: 0.9996 - val_loss: 0.3921 - val_accuracy: 0.8606 - val_f1_score: 0.4017 - val_precision: 0.2517 - val_recall: 0.9953\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 4370s 13s/step - loss: 0.0687 - accuracy: 0.9854 - f1_score: 0.4179 - precision: 0.2642 - recall: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9471 - val_f1_score: 0.4145 - val_precision: 0.2617 - val_recall: 0.9977\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 4380s 13s/step - loss: 0.0465 - accuracy: 0.9936 - f1_score: 0.4198 - precision: 0.2657 - recall: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9421 - val_f1_score: 0.4137 - val_precision: 0.2610 - val_recall: 0.9973\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 4378s 13s/step - loss: 0.0344 - accuracy: 0.9966 - f1_score: 0.4225 - precision: 0.2679 - recall: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9428 - val_f1_score: 0.4181 - val_precision: 0.2645 - val_recall: 0.9977\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 4378s 13s/step - loss: 0.0263 - accuracy: 0.9981 - f1_score: 0.4239 - precision: 0.2690 - recall: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9650 - val_f1_score: 0.4204 - val_precision: 0.2663 - val_recall: 0.9980\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 4378s 13s/step - loss: 0.0216 - accuracy: 0.9988 - f1_score: 0.4252 - precision: 0.2700 - recall: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9616 - val_f1_score: 0.4225 - val_precision: 0.2680 - val_recall: 0.9980\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 4376s 13s/step - loss: 0.0187 - accuracy: 0.9992 - f1_score: 0.4267 - precision: 0.2712 - recall: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9613 - val_f1_score: 0.4233 - val_precision: 0.2686 - val_recall: 0.9980\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 4375s 13s/step - loss: 0.0154 - accuracy: 0.9994 - f1_score: 0.4271 - precision: 0.2716 - recall: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9633 - val_f1_score: 0.4247 - val_precision: 0.2698 - val_recall: 0.9980\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 4373s 13s/step - loss: 0.0155 - accuracy: 0.9995 - f1_score: 0.4277 - precision: 0.2721 - recall: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9653 - val_f1_score: 0.4268 - val_precision: 0.2714 - val_recall: 0.9983\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 4376s 13s/step - loss: 0.0146 - accuracy: 0.9996 - f1_score: 0.4297 - precision: 0.2737 - recall: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9636 - val_f1_score: 0.4251 - val_precision: 0.2701 - val_recall: 0.9980\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 4384s 13s/step - loss: 0.0126 - accuracy: 0.9997 - f1_score: 0.4294 - precision: 0.2734 - recall: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9613 - val_f1_score: 0.4258 - val_precision: 0.2707 - val_recall: 0.9977\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 4381s 13s/step - loss: 0.0119 - accuracy: 0.9996 - f1_score: 0.4303 - precision: 0.2742 - recall: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9657 - val_f1_score: 0.4273 - val_precision: 0.2719 - val_recall: 0.9977\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 4384s 13s/step - loss: 0.0098 - accuracy: 0.9999 - f1_score: 0.4316 - precision: 0.2752 - recall: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9680 - val_f1_score: 0.4292 - val_precision: 0.2734 - val_recall: 0.9983\n"
     ]
    }
   ],
   "source": [
    "model_inceptionresnetv2 = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(input_shape=input_shapeIR+(3,), \n",
    "                                                                                      include_top=False, weights=None)\n",
    "\n",
    "inceptionresnetv2 = keras.Sequential([\n",
    "    model_inceptionresnetv2,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "inceptionresnetv2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_inceptionresnetv2 = inceptionresnetv2.fit(train_batchesIR,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batchesIR, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 207s - 207s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9683250414593698,\n",
       " 0.9685709623150446,\n",
       " 0.9683250414593698,\n",
       " 0.9683220455428999)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(inceptionresnetv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 203s - loss: 0.1008 - accuracy: 0.9683 - f1_score: 0.4269 - precision: 0.2715 - recall: 0.9995 - 203s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = inceptionresnetv2.evaluate(test_batchesIR, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 244). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/inceptionresnetv2_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/inceptionresnetv2_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "inceptionresnetv2.save(\"models/inceptionresnetv2_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapeX = (128,71)\n",
    "\n",
    "train_msX,train_labelsX = preprocess_dataset(train_files, input_shapeX)\n",
    "test_msX,test_labelsX = preprocess_dataset(test_files, input_shapeX)\n",
    "val_msX,val_labelsX = preprocess_dataset(val_files, input_shapeX)\n",
    "\n",
    "train_datasetX = tf.data.Dataset.from_tensor_slices((train_msX, train_labelsX))\n",
    "test_datasetX = tf.data.Dataset.from_tensor_slices((test_msX, test_labelsX))\n",
    "val_datasetX = tf.data.Dataset.from_tensor_slices((val_msX, val_labelsX))\n",
    "\n",
    "train_batchesX = train_datasetX.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "test_batchesX = test_datasetX.batch(batch_size)\n",
    "val_batchesX = val_datasetX.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 2656s 8s/step - loss: 1.1099 - accuracy: 0.6464 - f1_score: 0.3625 - precision: 0.2881 - recall: 0.7293 - val_loss: 2.3378 - val_accuracy: 0.1040 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2687s 8s/step - loss: 0.2008 - accuracy: 0.9397 - f1_score: 0.4437 - precision: 0.2854 - recall: 0.9971 - val_loss: 3.1698 - val_accuracy: 0.1670 - val_f1_score: 0.2429 - val_precision: 0.1558 - val_recall: 0.5510\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2743s 8s/step - loss: 0.0678 - accuracy: 0.9834 - f1_score: 0.4558 - precision: 0.2953 - recall: 0.9993 - val_loss: 0.1886 - val_accuracy: 0.9380 - val_f1_score: 0.4632 - val_precision: 0.3017 - val_recall: 0.9973\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2679s 8s/step - loss: 0.0264 - accuracy: 0.9956 - f1_score: 0.4621 - precision: 0.3005 - recall: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9599 - val_f1_score: 0.4609 - val_precision: 0.2998 - val_recall: 0.9970\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2697s 8s/step - loss: 0.0107 - accuracy: 0.9994 - f1_score: 0.4639 - precision: 0.3020 - recall: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9684 - val_f1_score: 0.4669 - val_precision: 0.3049 - val_recall: 0.9973\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2683s 8s/step - loss: 0.0094 - accuracy: 0.9992 - f1_score: 0.4648 - precision: 0.3028 - recall: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9684 - val_f1_score: 0.4719 - val_precision: 0.3091 - val_recall: 0.9980\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2675s 8s/step - loss: 0.0055 - accuracy: 0.9999 - f1_score: 0.4670 - precision: 0.3047 - recall: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9694 - val_f1_score: 0.4671 - val_precision: 0.3050 - val_recall: 0.9980\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2630s 8s/step - loss: 0.0042 - accuracy: 0.9999 - f1_score: 0.4678 - precision: 0.3054 - recall: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9741 - val_f1_score: 0.4659 - val_precision: 0.3039 - val_recall: 0.9980\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2631s 8s/step - loss: 0.0081 - accuracy: 0.9992 - f1_score: 0.4693 - precision: 0.3067 - recall: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9741 - val_f1_score: 0.4692 - val_precision: 0.3067 - val_recall: 0.9987\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2682s 8s/step - loss: 0.0036 - accuracy: 0.9999 - f1_score: 0.4706 - precision: 0.3077 - recall: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9714 - val_f1_score: 0.4746 - val_precision: 0.3114 - val_recall: 0.9977\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 2682s 8s/step - loss: 0.0036 - accuracy: 0.9997 - f1_score: 0.4720 - precision: 0.3090 - recall: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9717 - val_f1_score: 0.4718 - val_precision: 0.3090 - val_recall: 0.9980\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 2674s 8s/step - loss: 0.0036 - accuracy: 0.9999 - f1_score: 0.4729 - precision: 0.3097 - recall: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9717 - val_f1_score: 0.4736 - val_precision: 0.3105 - val_recall: 0.9983\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 2659s 8s/step - loss: 0.0026 - accuracy: 1.0000 - f1_score: 0.4736 - precision: 0.3104 - recall: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9724 - val_f1_score: 0.4732 - val_precision: 0.3102 - val_recall: 0.9980\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 2699s 8s/step - loss: 0.0038 - accuracy: 0.9997 - f1_score: 0.4742 - precision: 0.3109 - recall: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9727 - val_f1_score: 0.4748 - val_precision: 0.3116 - val_recall: 0.9980\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2683s 8s/step - loss: 0.0022 - accuracy: 1.0000 - f1_score: 0.4749 - precision: 0.3115 - recall: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9737 - val_f1_score: 0.4765 - val_precision: 0.3130 - val_recall: 0.9980\n"
     ]
    }
   ],
   "source": [
    "model_xception = tf.keras.applications.xception.Xception(input_shape=input_shapeX+(3,), include_top=False, weights=None)\n",
    "\n",
    "xception = keras.Sequential([\n",
    "    model_xception,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "xception.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_xception = xception.fit(train_batchesX,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batchesX, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 148s - 148s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9714759535655058,\n",
       " 0.9715861116605584,\n",
       " 0.9714759535655058,\n",
       " 0.9714719244720276)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 147s - loss: 0.0934 - accuracy: 0.9715 - f1_score: 0.4727 - precision: 0.3097 - recall: 0.9987 - 147s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = xception.evaluate(test_batchesX, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/xception_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/xception_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "xception.save(\"models/xception_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 550s 2s/step - loss: 0.8625 - accuracy: 0.6927 - f1_score: 0.3949 - precision: 0.2533 - recall: 0.9046 - val_loss: 2.8157 - val_accuracy: 0.1040 - val_f1_score: 0.1551 - val_precision: 0.1041 - val_recall: 0.3042\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 0.2541 - accuracy: 0.9133 - f1_score: 0.4375 - precision: 0.2803 - recall: 0.9967 - val_loss: 0.3668 - val_accuracy: 0.8747 - val_f1_score: 0.4361 - val_precision: 0.2797 - val_recall: 0.9907\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 0.1100 - accuracy: 0.9638 - f1_score: 0.4515 - precision: 0.2917 - recall: 0.9993 - val_loss: 0.2036 - val_accuracy: 0.9350 - val_f1_score: 0.4516 - val_precision: 0.2919 - val_recall: 0.9977\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 0.0441 - accuracy: 0.9862 - f1_score: 0.4575 - precision: 0.2967 - recall: 0.9998 - val_loss: 0.2021 - val_accuracy: 0.9387 - val_f1_score: 0.4588 - val_precision: 0.2980 - val_recall: 0.9977\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 0.0121 - accuracy: 0.9976 - f1_score: 0.4615 - precision: 0.3000 - recall: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9582 - val_f1_score: 0.4657 - val_precision: 0.3038 - val_recall: 0.9983\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 0.0031 - accuracy: 0.9997 - f1_score: 0.4657 - precision: 0.3036 - recall: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9643 - val_f1_score: 0.4713 - val_precision: 0.3086 - val_recall: 0.9977\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 0.0011 - accuracy: 1.0000 - f1_score: 0.4673 - precision: 0.3049 - recall: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9640 - val_f1_score: 0.4717 - val_precision: 0.3090 - val_recall: 0.9980\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 7.7199e-04 - accuracy: 1.0000 - f1_score: 0.4686 - precision: 0.3061 - recall: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9646 - val_f1_score: 0.4729 - val_precision: 0.3099 - val_recall: 0.9980\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 6.3610e-04 - accuracy: 1.0000 - f1_score: 0.4698 - precision: 0.3071 - recall: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9653 - val_f1_score: 0.4737 - val_precision: 0.3107 - val_recall: 0.9980\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 537s 2s/step - loss: 5.5209e-04 - accuracy: 1.0000 - f1_score: 0.4710 - precision: 0.3081 - recall: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9653 - val_f1_score: 0.4750 - val_precision: 0.3118 - val_recall: 0.9980\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 4.9323e-04 - accuracy: 1.0000 - f1_score: 0.4719 - precision: 0.3089 - recall: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9657 - val_f1_score: 0.4757 - val_precision: 0.3124 - val_recall: 0.9980\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 4.4928e-04 - accuracy: 1.0000 - f1_score: 0.4725 - precision: 0.3094 - recall: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9657 - val_f1_score: 0.4766 - val_precision: 0.3132 - val_recall: 0.9980\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 537s 2s/step - loss: 4.1496e-04 - accuracy: 1.0000 - f1_score: 0.4730 - precision: 0.3099 - recall: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9653 - val_f1_score: 0.4773 - val_precision: 0.3138 - val_recall: 0.9980\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 537s 2s/step - loss: 3.8732e-04 - accuracy: 1.0000 - f1_score: 0.4736 - precision: 0.3103 - recall: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9653 - val_f1_score: 0.4777 - val_precision: 0.3141 - val_recall: 0.9980\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 536s 2s/step - loss: 3.6448e-04 - accuracy: 1.0000 - f1_score: 0.4739 - precision: 0.3106 - recall: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9653 - val_f1_score: 0.4783 - val_precision: 0.3146 - val_recall: 0.9980\n"
     ]
    }
   ],
   "source": [
    "model_mobilenet = tf.keras.applications.mobilenet.MobileNet(input_shape=input_shape+(3,), include_top=False, weights=None)\n",
    "\n",
    "mobilenet = keras.Sequential([\n",
    "    model_mobilenet,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "mobilenet.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_mobilenet = mobilenet.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 21s - 21s/epoch - 222ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9646766169154228, 0.964804337226236, 0.9646766169154228, 0.9646772641826247)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 21s - loss: 0.1363 - accuracy: 0.9647 - f1_score: 0.4800 - precision: 0.3161 - recall: 0.9980 - 21s/epoch - 218ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = mobilenet.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_128_input with unsupported characters which will be renamed to mobilenet_1_00_128_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenet_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenet_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "mobilenet.save(\"models/mobilenet_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapeMN2 = (128,64)\n",
    "\n",
    "train_msMN2,train_labelsMN2 = preprocess_dataset(train_files, input_shapeMN2)\n",
    "test_msMN2,test_labelsMN2 = preprocess_dataset(test_files, input_shapeMN2)\n",
    "val_msMN2,val_labelsMN2 = preprocess_dataset(val_files, input_shapeMN2)\n",
    "\n",
    "train_datasetMN2 = tf.data.Dataset.from_tensor_slices((train_msMN2, train_labelsMN2))\n",
    "test_datasetMN2 = tf.data.Dataset.from_tensor_slices((test_msMN2, test_labelsMN2))\n",
    "val_datasetMN2 = tf.data.Dataset.from_tensor_slices((val_msMN2, val_labelsMN2))\n",
    "\n",
    "train_batchesMN2 = train_datasetMN2.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "test_batchesMN2 = test_datasetMN2.batch(batch_size)\n",
    "val_batchesMN2 = val_datasetMN2.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/marload/ConvNets-TensorFlow2\n",
    "from tensorflow.keras import layers, Sequential, Model\n",
    "\n",
    "\n",
    "def ReLU6():\n",
    "    return layers.Lambda(lambda x: tf.nn.relu6(x))\n",
    "\n",
    "\n",
    "class LinearBottleNeck(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, strides=1, t=6):\n",
    "        super(LinearBottleNeck, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.strides = strides\n",
    "\n",
    "        self.residual = Sequential([\n",
    "            layers.Conv2D(in_channels * t,\n",
    "                          (1, 1),\n",
    "                          strides=1,\n",
    "                          padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            ReLU6(),\n",
    "            layers.DepthwiseConv2D((3, 3),\n",
    "                                   strides=strides,\n",
    "                                   padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            ReLU6(),\n",
    "            layers.Conv2D(out_channels,\n",
    "                          (1, 1),\n",
    "                          strides=1,\n",
    "                          padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        residual = self.residual(x, training=training)\n",
    "\n",
    "        if self.strides == 1 and self.in_channels == self.out_channels:\n",
    "            residual += x\n",
    "\n",
    "        return residual\n",
    "\n",
    "\n",
    "class MobileNetV2(Model):\n",
    "    def __init__(self, num_classes, input_shape):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        self.front = Sequential([\n",
    "            layers.Input(input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            ReLU6()\n",
    "        ])\n",
    "        self.stage1 = LinearBottleNeck(32, 16, 1, 1)\n",
    "        self.stage2 = self._make_stage(2, 16, 24, 2, 6)\n",
    "        self.stage3 = self._make_stage(3, 24, 32, 2, 6)\n",
    "        self.stage4 = self._make_stage(4, 32, 64, 2, 6)\n",
    "        self.stage5 = self._make_stage(3, 64, 96, 1, 6)\n",
    "        self.stage6 = self._make_stage(3, 96, 160, 1, 6)\n",
    "        self.stage7 = LinearBottleNeck(160, 320, 1, 6)\n",
    "\n",
    "        self.conv1 = layers.Conv2D(filters=1280,\n",
    "                                   kernel_size=(1, 1),\n",
    "                                   strides=1,\n",
    "                                   padding=\"same\")\n",
    "        self.ap = layers.AveragePooling2D((7, 7))\n",
    "        self.fc = layers.Dense(num_classes, activation='softmax')\n",
    "    def _make_stage(self, repeat, in_channels, out_channels, strides, t):\n",
    "        nets = Sequential()\n",
    "        nets.add(LinearBottleNeck(in_channels, out_channels, strides, t))\n",
    "\n",
    "        while repeat - 1:\n",
    "            nets.add(LinearBottleNeck(out_channels, out_channels, 1, t))\n",
    "            repeat -= 1\n",
    "        return nets\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.front(inputs)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ap(x)\n",
    "        #x = tf.reshape(x, (x.shape[0], -1))\n",
    "        x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def mobilenetv2(num_classes, input_shape):\n",
    "    return MobileNetV2(num_classes, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 1899s 6s/step - loss: 0.6017 - accuracy: 0.7787 - f1_score: 0.7571 - precision: 0.8156 - recall: 0.7292 - val_loss: 4.2114 - val_accuracy: 0.0946 - val_f1_score: 0.0949 - val_precision: 0.0949 - val_recall: 0.0949\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 1882s 6s/step - loss: 0.1898 - accuracy: 0.9348 - f1_score: 0.9347 - precision: 0.9412 - recall: 0.9284 - val_loss: 1.1019 - val_accuracy: 0.5987 - val_f1_score: 0.6028 - val_precision: 0.6605 - val_recall: 0.5555\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 1880s 6s/step - loss: 0.0963 - accuracy: 0.9673 - f1_score: 0.9678 - precision: 0.9708 - recall: 0.9648 - val_loss: 0.1750 - val_accuracy: 0.9370 - val_f1_score: 0.9351 - val_precision: 0.9393 - val_recall: 0.9309\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 1881s 6s/step - loss: 0.0632 - accuracy: 0.9785 - f1_score: 0.9783 - precision: 0.9798 - recall: 0.9768 - val_loss: 0.0794 - val_accuracy: 0.9724 - val_f1_score: 0.9724 - val_precision: 0.9742 - val_recall: 0.9706\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 1879s 6s/step - loss: 0.0401 - accuracy: 0.9870 - f1_score: 0.9869 - precision: 0.9876 - recall: 0.9862 - val_loss: 0.0953 - val_accuracy: 0.9677 - val_f1_score: 0.9669 - val_precision: 0.9696 - val_recall: 0.9643\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 1879s 6s/step - loss: 0.0227 - accuracy: 0.9930 - f1_score: 0.9928 - precision: 0.9933 - recall: 0.9924 - val_loss: 0.0603 - val_accuracy: 0.9811 - val_f1_score: 0.9812 - val_precision: 0.9819 - val_recall: 0.9806\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 1871s 6s/step - loss: 0.0128 - accuracy: 0.9963 - f1_score: 0.9959 - precision: 0.9961 - recall: 0.9958 - val_loss: 0.0613 - val_accuracy: 0.9838 - val_f1_score: 0.9847 - val_precision: 0.9853 - val_recall: 0.9840\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 1875s 6s/step - loss: 0.0143 - accuracy: 0.9959 - f1_score: 0.9958 - precision: 0.9960 - recall: 0.9956 - val_loss: 0.0633 - val_accuracy: 0.9835 - val_f1_score: 0.9835 - val_precision: 0.9840 - val_recall: 0.9830\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 1870s 6s/step - loss: 0.0062 - accuracy: 0.9985 - f1_score: 0.9986 - precision: 0.9986 - recall: 0.9985 - val_loss: 0.0463 - val_accuracy: 0.9852 - val_f1_score: 0.9855 - val_precision: 0.9857 - val_recall: 0.9854\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 1870s 6s/step - loss: 0.0082 - accuracy: 0.9977 - f1_score: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0717 - val_accuracy: 0.9808 - val_f1_score: 0.9815 - val_precision: 0.9824 - val_recall: 0.9807\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 1871s 6s/step - loss: 0.0067 - accuracy: 0.9981 - f1_score: 0.9975 - precision: 0.9975 - recall: 0.9974 - val_loss: 0.0549 - val_accuracy: 0.9852 - val_f1_score: 0.9850 - val_precision: 0.9857 - val_recall: 0.9844\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 1870s 6s/step - loss: 0.0131 - accuracy: 0.9961 - f1_score: 0.9961 - precision: 0.9962 - recall: 0.9959 - val_loss: 0.0605 - val_accuracy: 0.9818 - val_f1_score: 0.9813 - val_precision: 0.9822 - val_recall: 0.9804\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 1871s 6s/step - loss: 0.0038 - accuracy: 0.9990 - f1_score: 0.9990 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0501 - val_accuracy: 0.9845 - val_f1_score: 0.9844 - val_precision: 0.9847 - val_recall: 0.9840\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 1863s 6s/step - loss: 0.0024 - accuracy: 0.9994 - f1_score: 0.9994 - precision: 0.9994 - recall: 0.9993 - val_loss: 0.0496 - val_accuracy: 0.9872 - val_f1_score: 0.9872 - val_precision: 0.9880 - val_recall: 0.9864\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 1861s 6s/step - loss: 0.0031 - accuracy: 0.9992 - f1_score: 0.9992 - precision: 0.9992 - recall: 0.9992 - val_loss: 0.0470 - val_accuracy: 0.9875 - val_f1_score: 0.9874 - val_precision: 0.9877 - val_recall: 0.9870\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2 = mobilenetv2(len(labels), input_shapeMN2+(3,))\n",
    "\n",
    "mobilenetv2.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_mobilenetv2 = mobilenetv2.fit(train_batchesMN2,\n",
    "                             epochs=epoch,\n",
    "                             validation_data=val_batchesMN2,\n",
    "                             verbose=1,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 146s - loss: 0.0594 - accuracy: 0.9831 - f1_score: 0.9835 - precision: 0.9844 - recall: 0.9826 - 146s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = mobilenetv2.evaluate(test_batchesMN2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenetv2_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenetv2_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2.save(\"models/mobilenetv2_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV3Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "\n",
    "    return new_v\n",
    "\n",
    "def get_layer(layer_name, layer_dict, default_layer):\n",
    "    if layer_name is None:\n",
    "        return default_layer\n",
    "\n",
    "    if layer_name in layer_dict.keys():\n",
    "        return layer_dict.get(layer_name)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Layer [{layer_name}] is not implemented\")\n",
    "        \n",
    "class LayerNamespaceWrapper(tf.keras.layers.Layer):\n",
    "    \"\"\"`NameWrapper` defines auxiliary layer that wraps given `layer`\n",
    "    with given `name`. This is useful for better visualization of network\n",
    "    in TensorBoard.\n",
    "    Default behavior of namespaces defined with nested `tf.keras.Sequential`\n",
    "    layers is to keep only the most high-level `tf.keras.Sequential` name.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            layer: tf.keras.layers.Layer,\n",
    "            name: str,\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "        self.wrapped_layer = tf.keras.Sequential(\n",
    "            [\n",
    "                layer,\n",
    "            ],\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.wrapped_layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Identity\")\n",
    "\n",
    "    def call(self, input):\n",
    "        return input\n",
    "\n",
    "\n",
    "class ReLU6(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"ReLU6\")\n",
    "        self.relu6 = tf.keras.layers.ReLU(max_value=6, name=\"ReLU6\")\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.relu6(input)\n",
    "\n",
    "\n",
    "class HardSigmoid(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"HardSigmoid\")\n",
    "        self.relu6 = ReLU6()\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.relu6(input + 3.0) / 6.0\n",
    "\n",
    "\n",
    "class HardSwish(tf.keras.layers.Layer):\n",
    "    def __init__(self, name=\"HardSwish\"):\n",
    "        super().__init__(name=name)\n",
    "        self.hard_sigmoid = HardSigmoid()\n",
    "\n",
    "    def call(self, input):\n",
    "        return input * self.hard_sigmoid(input)\n",
    "\n",
    "\n",
    "class Squeeze(tf.keras.layers.Layer):\n",
    "    \"\"\"Squeeze the second and third dimensions of given tensor.\n",
    "    (batch, 1, 1, channels) -> (batch, channels)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Squeeze\")\n",
    "\n",
    "    def call(self, input):\n",
    "        x = tf.keras.backend.squeeze(input, 1)\n",
    "        x = tf.keras.backend.squeeze(x, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GlobalAveragePooling2D(tf.keras.layers.Layer):\n",
    "    \"\"\"Return tensor of output shape (batch_size, rows, cols, channels)\n",
    "    where rows and cols are equal to 1. Output shape of\n",
    "    `tf.keras.layer.GlobalAveragePooling2D` is (batch_size, channels),\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"GlobalAveragePooling2D\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pool_size = tuple(map(int, input_shape[1:3]))\n",
    "        self.gap = tf.keras.layers.AveragePooling2D(\n",
    "            pool_size=pool_size,\n",
    "            name=f\"AvgPool{pool_size[0]}x{pool_size[1]}\",\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.gap(input)\n",
    "\n",
    "\n",
    "class BatchNormalization(tf.keras.layers.Layer):\n",
    "    \"\"\"Searching fo MobileNetV3: All our convolutional layers\n",
    "    use batch-normalization layers with average decay of 0.99.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            momentum: float=0.99,\n",
    "            name=\"BatchNormalization\",\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.bn = tf.keras.layers.BatchNormalization(\n",
    "            momentum=0.99,\n",
    "            name=\"BatchNormalization\",\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.bn(input)\n",
    "\n",
    "\n",
    "class ConvNormAct(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            filters: int,\n",
    "            kernel_size: int=3,\n",
    "            stride: int=1,\n",
    "            padding: int=0,\n",
    "            norm_layer: str=None,\n",
    "            act_layer: str=\"relu\",\n",
    "            use_bias: bool=True,\n",
    "            l2_reg: float=1e-5,\n",
    "            name: str=\"ConvNormAct\",\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        if padding > 0:\n",
    "            self.pad = tf.keras.layers.ZeroPadding2D(\n",
    "                padding=padding,\n",
    "                name=f\"Padding{padding}x{padding}\",\n",
    "            )\n",
    "        else:\n",
    "            self.pad = Identity()\n",
    "\n",
    "        self.conv = tf.keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=stride,\n",
    "            name=f\"Conv{kernel_size}x{kernel_size}\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
    "            use_bias=use_bias,\n",
    "        )\n",
    "\n",
    "        _available_normalization = {\n",
    "            \"bn\": BatchNormalization(),\n",
    "            }\n",
    "        self.norm = get_layer(norm_layer, _available_normalization, Identity())\n",
    "\n",
    "        _available_activation = {\n",
    "            \"relu\": tf.keras.layers.ReLU(name=\"ReLU\"),\n",
    "            \"relu6\": ReLU6(),\n",
    "            \"hswish\": HardSwish(),\n",
    "            \"hsigmoid\": HardSigmoid(),\n",
    "            \"softmax\": tf.keras.layers.Softmax(name=\"Softmax\"),\n",
    "        }\n",
    "        self.act = get_layer(act_layer, _available_activation, Identity())\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.pad(input)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bneck(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            out_channels: int,\n",
    "            exp_channels: int,\n",
    "            kernel_size: int,\n",
    "            stride: int,\n",
    "            use_se: bool,\n",
    "            act_layer: str,\n",
    "            l2_reg: float=1e-5,\n",
    "    ):\n",
    "        super().__init__(name=\"Bneck\")\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.use_se = use_se\n",
    "\n",
    "        # Expand\n",
    "        self.expand = ConvNormAct(\n",
    "            exp_channels,\n",
    "            kernel_size=1,\n",
    "            norm_layer=\"bn\",\n",
    "            act_layer=act_layer,\n",
    "            use_bias=False,\n",
    "            l2_reg=l2_reg,\n",
    "            name=\"Expand\",\n",
    "        )\n",
    "\n",
    "        # Depthwise\n",
    "        dw_padding = (kernel_size - 1) // 2\n",
    "        self.pad = tf.keras.layers.ZeroPadding2D(\n",
    "            padding=dw_padding,\n",
    "            name=f\"Depthwise/Padding{dw_padding}x{dw_padding}\",\n",
    "        )\n",
    "        self.depthwise = tf.keras.layers.DepthwiseConv2D(\n",
    "            kernel_size=kernel_size,\n",
    "            strides=stride,\n",
    "            name=f\"Depthwise/DWConv{kernel_size}x{kernel_size}\",\n",
    "            depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
    "            use_bias=False,\n",
    "        )\n",
    "        self.bn = BatchNormalization(name=\"Depthwise/BatchNormalization\")\n",
    "        if self.use_se:\n",
    "            self.se = SEBottleneck(\n",
    "                l2_reg=l2_reg,\n",
    "                name=\"Depthwise/SEBottleneck\",\n",
    "            )\n",
    "\n",
    "        _available_activation = {\n",
    "            \"relu\": tf.keras.layers.ReLU(name=\"Depthwise/ReLU\"),\n",
    "            \"hswish\": HardSwish(name=\"Depthwise/HardSwish\"),\n",
    "        }\n",
    "        self.act = get_layer(act_layer, _available_activation, Identity())\n",
    "\n",
    "        # Project\n",
    "        self.project = ConvNormAct(\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            norm_layer=\"bn\",\n",
    "            act_layer=None,\n",
    "            use_bias=False,\n",
    "            l2_reg=l2_reg,\n",
    "            name=\"Project\",\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.in_channels = int(input_shape[3])\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.expand(input)\n",
    "        x = self.pad(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn(x)\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "        x = self.act(x)\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
    "            return input + x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class SEBottleneck(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            reduction: int=4,\n",
    "            l2_reg: float=0.01,\n",
    "            name: str=\"SEBottleneck\",\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.reduction = reduction\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_channels = int(input_shape[3])\n",
    "        self.gap = GlobalAveragePooling2D()\n",
    "        self.conv1 = ConvNormAct(\n",
    "            input_channels // self.reduction,\n",
    "            kernel_size=1,\n",
    "            norm_layer=None,\n",
    "            act_layer=\"relu\",\n",
    "            use_bias=False,\n",
    "            l2_reg=self.l2_reg,\n",
    "            name=\"Squeeze\",\n",
    "        )\n",
    "        self.conv2 = ConvNormAct(\n",
    "            input_channels,\n",
    "            kernel_size=1,\n",
    "            norm_layer=None,\n",
    "            act_layer=\"hsigmoid\",\n",
    "            use_bias=False,\n",
    "            l2_reg=self.l2_reg,\n",
    "            name=\"Excite\",\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.gap(input)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return input * x\n",
    "\n",
    "\n",
    "class LastStage(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            penultimate_channels: int,\n",
    "            last_channels: int,\n",
    "            num_classes: int,\n",
    "            l2_reg: float,\n",
    "    ):\n",
    "        super().__init__(name=\"LastStage\")\n",
    "\n",
    "        self.conv1 = ConvNormAct(\n",
    "            penultimate_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            norm_layer=\"bn\",\n",
    "            act_layer=\"hswish\",\n",
    "            use_bias=False,\n",
    "            l2_reg=l2_reg,\n",
    "        )\n",
    "        self.gap = GlobalAveragePooling2D()\n",
    "        self.conv2 = ConvNormAct(\n",
    "            last_channels,\n",
    "            kernel_size=1,\n",
    "            norm_layer=None,\n",
    "            act_layer=\"hswish\",\n",
    "            l2_reg=l2_reg,\n",
    "        )\n",
    "        self.dropout = tf.keras.layers.Dropout(\n",
    "            rate=0.2,\n",
    "            name=\"Dropout\",\n",
    "        )\n",
    "        self.conv3 = ConvNormAct(\n",
    "            num_classes,\n",
    "            kernel_size=1,\n",
    "            norm_layer=None,\n",
    "            act_layer=\"softmax\",\n",
    "            l2_reg=l2_reg,\n",
    "        )\n",
    "        self.squeeze = Squeeze()\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.gap(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.squeeze(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV3Small(tf.keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int=1001,\n",
    "            width_multiplier: float=1.0,\n",
    "            name: str=\"MobileNetV3_Small\",\n",
    "            divisible_by: int=8,\n",
    "            l2_reg: float=1e-5,\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        # First layer\n",
    "        self.first_layer = ConvNormAct(\n",
    "            16,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            norm_layer=\"bn\",\n",
    "            act_layer=\"hswish\",\n",
    "            use_bias=False,\n",
    "            l2_reg=l2_reg,\n",
    "            name=\"FirstLayer\",\n",
    "        )\n",
    "\n",
    "        # Bottleneck layers\n",
    "        self.bneck_settings = [\n",
    "            # k   exp   out  SE      NL         s\n",
    "            [ 3,  16,   16,  True,   \"relu\",    2 ],\n",
    "            [ 3,  72,   24,  False,  \"relu\",    2 ],\n",
    "            [ 3,  88,   24,  False,  \"relu\",    1 ],\n",
    "            [ 5,  96,   40,  True,   \"hswish\",  2 ],\n",
    "            [ 5,  240,  40,  True,   \"hswish\",  1 ],\n",
    "            [ 5,  240,  40,  True,   \"hswish\",  1 ],\n",
    "            [ 5,  120,  48,  True,   \"hswish\",  1 ],\n",
    "            [ 5,  144,  48,  True,   \"hswish\",  1 ],\n",
    "            [ 5,  288,  96,  True,   \"hswish\",  2 ],\n",
    "            [ 5,  576,  96,  True,   \"hswish\",  1 ],\n",
    "            [ 5,  576,  96,  True,   \"hswish\",  1 ],\n",
    "        ]\n",
    "\n",
    "        self.bneck = tf.keras.Sequential(name=\"Bneck\")\n",
    "        for idx, (k, exp, out, SE, NL, s) in enumerate(self.bneck_settings):\n",
    "            out_channels = _make_divisible(out * width_multiplier, divisible_by)\n",
    "            exp_channels = _make_divisible(exp * width_multiplier, divisible_by)\n",
    "\n",
    "            self.bneck.add(\n",
    "                LayerNamespaceWrapper(\n",
    "                    Bneck(\n",
    "                        out_channels=out_channels,\n",
    "                        exp_channels=exp_channels,\n",
    "                        kernel_size=k,\n",
    "                        stride=s,\n",
    "                        use_se=SE,\n",
    "                        act_layer=NL,\n",
    "                    ),\n",
    "                    name=f\"Bneck{idx}\")\n",
    "            )\n",
    "\n",
    "        # Last stage\n",
    "        penultimate_channels = _make_divisible(576 * width_multiplier, divisible_by)\n",
    "        last_channels = _make_divisible(1_280 * width_multiplier, divisible_by)\n",
    "\n",
    "        self.last_stage = LastStage(\n",
    "            penultimate_channels,\n",
    "            last_channels,\n",
    "            num_classes,\n",
    "            l2_reg=l2_reg,\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.first_layer(input)\n",
    "        x = self.bneck(x)\n",
    "        x = self.last_stage(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def build_mobilenetv3(\n",
    "        model_type: str,\n",
    "        input_shape: Tuple[int, int, int]=(224, 224, 3),\n",
    "        num_classes: int=1001,\n",
    "        width_multiplier: float=1.0,\n",
    "        l2_reg: float=1e-5,\n",
    "):\n",
    "    assert len(input_shape) == 3, \"`input_shape` should be a tuple representing input data shape (height, width, channels)\"\n",
    "\n",
    "    if model_type == 'small':\n",
    "        model = MobileNetV3Small(\n",
    "            num_classes=num_classes,\n",
    "            width_multiplier=width_multiplier,\n",
    "            l2_reg=l2_reg)\n",
    "    elif model_type == 'large':\n",
    "        model = MobileNetV3Large(\n",
    "            num_classes=num_classes,\n",
    "            width_multiplier=width_multiplier,\n",
    "            l2_reg=l2_reg)\n",
    "\n",
    "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
    "    output_tensor = model(input_tensor)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[model.input],\n",
    "        outputs=[model.output],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 190s 543ms/step - loss: 0.8414 - accuracy: 0.7148 - f1_score: 0.6750 - precision: 0.7722 - recall: 0.6344 - val_loss: 2.3762 - val_accuracy: 0.1875 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 176s 536ms/step - loss: 0.2661 - accuracy: 0.9240 - f1_score: 0.9235 - precision: 0.9357 - recall: 0.9118 - val_loss: 0.3539 - val_accuracy: 0.9020 - val_f1_score: 0.8982 - val_precision: 0.9253 - val_recall: 0.8732\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 180s 548ms/step - loss: 0.1663 - accuracy: 0.9592 - f1_score: 0.9597 - precision: 0.9651 - recall: 0.9545 - val_loss: 0.2693 - val_accuracy: 0.9276 - val_f1_score: 0.9299 - val_precision: 0.9373 - val_recall: 0.9227\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 182s 552ms/step - loss: 0.1167 - accuracy: 0.9764 - f1_score: 0.9764 - precision: 0.9795 - recall: 0.9734 - val_loss: 0.1926 - val_accuracy: 0.9512 - val_f1_score: 0.9506 - val_precision: 0.9540 - val_recall: 0.9473\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 186s 565ms/step - loss: 0.0851 - accuracy: 0.9881 - f1_score: 0.9882 - precision: 0.9897 - recall: 0.9867 - val_loss: 0.1951 - val_accuracy: 0.9519 - val_f1_score: 0.9526 - val_precision: 0.9568 - val_recall: 0.9485\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 185s 562ms/step - loss: 0.0681 - accuracy: 0.9944 - f1_score: 0.9944 - precision: 0.9951 - recall: 0.9938 - val_loss: 0.1926 - val_accuracy: 0.9599 - val_f1_score: 0.9600 - val_precision: 0.9616 - val_recall: 0.9584\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 168s 509ms/step - loss: 0.0593 - accuracy: 0.9970 - f1_score: 0.9971 - precision: 0.9973 - recall: 0.9968 - val_loss: 0.1585 - val_accuracy: 0.9657 - val_f1_score: 0.9664 - val_precision: 0.9677 - val_recall: 0.9651\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 166s 503ms/step - loss: 0.0529 - accuracy: 0.9990 - f1_score: 0.9990 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.1532 - val_accuracy: 0.9673 - val_f1_score: 0.9681 - val_precision: 0.9687 - val_recall: 0.9674\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 167s 506ms/step - loss: 0.0493 - accuracy: 0.9997 - f1_score: 0.9997 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.1522 - val_accuracy: 0.9687 - val_f1_score: 0.9696 - val_precision: 0.9704 - val_recall: 0.9688\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 164s 500ms/step - loss: 0.0476 - accuracy: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9731 - val_f1_score: 0.9737 - val_precision: 0.9750 - val_recall: 0.9724\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 163s 497ms/step - loss: 0.0471 - accuracy: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9714 - val_f1_score: 0.9720 - val_precision: 0.9730 - val_recall: 0.9711\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 165s 503ms/step - loss: 0.0470 - accuracy: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9710 - val_f1_score: 0.9712 - val_precision: 0.9724 - val_recall: 0.9701\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 171s 520ms/step - loss: 0.0468 - accuracy: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9717 - val_f1_score: 0.9722 - val_precision: 0.9734 - val_recall: 0.9711\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 166s 506ms/step - loss: 0.0467 - accuracy: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9717 - val_f1_score: 0.9719 - val_precision: 0.9730 - val_recall: 0.9707\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 163s 495ms/step - loss: 0.0467 - accuracy: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9714 - val_f1_score: 0.9717 - val_precision: 0.9727 - val_recall: 0.9707\n"
     ]
    }
   ],
   "source": [
    "mobilenetv3small = build_mobilenetv3(\n",
    "    \"small\",\n",
    "    input_shape=input_shape+(3,),\n",
    "    num_classes=len(labels),\n",
    "    width_multiplier=1.0)\n",
    "\n",
    "mobilenetv3small.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_mobilenetv3small = mobilenetv3small.fit(train_batches,\n",
    "                             epochs=epoch,\n",
    "                             validation_data=val_batches,\n",
    "                             verbose=1,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 13s - 13s/epoch - 141ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9781094527363184,\n",
       " 0.9781833517010187,\n",
       " 0.9781094527363184,\n",
       " 0.9780986652581752)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(mobilenetv3small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 11s - loss: 0.1320 - accuracy: 0.9781 - f1_score: 0.9779 - precision: 0.9790 - recall: 0.9769 - 11s/epoch - 118ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = mobilenetv3small.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as Conv3x3_layer_call_fn, Conv3x3_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, BatchNormalization_layer_call_fn, BatchNormalization_layer_call_and_return_conditional_losses while saving (showing 5 of 749). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenetv3small_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenetv3small_no_weights\\assets\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE44EB7310> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE835DAC70> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE82ABF2B0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83BD5BE0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE82557F40> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83C26820> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7A12FA90> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7A127DC0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE4B6B24C0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE4B731670> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83AEEC10> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83B3D520> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83910760> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE82A41040> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83BB1520> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE82C8CB80> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83C3A5E0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE827308B0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE62E5E280> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7B3F4490> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE44DECC40> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE824841F0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE7C3384F0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7ACCE430> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7C56F190> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE7C2960A0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7BCC7A60> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7BCF8820> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE7C1A7EB0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE82A08AC0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE7B2AB310> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE83432400> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83BE50A0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83BE59A0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE833EBDC0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83B78A30> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83B61910> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE832221C0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83B0AE20> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE83B03460> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE83244310> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE837FF550> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE82AAE1C0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EE83048F40> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EE82B3A640> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "mobilenetv3small.save(\"models/mobilenetv3small_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV3Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV3Large(tf.keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int=1001,\n",
    "            width_multiplier: float=1.0,\n",
    "            name: str=\"MobileNetV3_Large\",\n",
    "            divisible_by: int=8,\n",
    "            l2_reg: float=1e-5,\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        # First layer\n",
    "        self.first_layer = ConvNormAct(\n",
    "            16,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            norm_layer=\"bn\",\n",
    "            act_layer=\"hswish\",\n",
    "            use_bias=False,\n",
    "            l2_reg=l2_reg,\n",
    "            name=\"FirstLayer\",\n",
    "        )\n",
    "\n",
    "        # Bottleneck layers\n",
    "        self.bneck_settings = [\n",
    "            # k   exp   out   SE      NL         s\n",
    "            [ 3,  16,   16,   False,  \"relu\",    1 ],\n",
    "            [ 3,  64,   24,   False,  \"relu\",    2 ],\n",
    "            [ 3,  72,   24,   False,  \"relu\",    1 ],\n",
    "            [ 5,  72,   40,   True,   \"relu\",    2 ],\n",
    "            [ 5,  120,  40,   True,   \"relu\",    1 ],\n",
    "            [ 5,  120,  40,   True,   \"relu\",    1 ],\n",
    "            [ 3,  240,  80,   False,  \"hswish\",  2 ],\n",
    "            [ 3,  200,  80,   False,  \"hswish\",  1 ],\n",
    "            [ 3,  184,  80,   False,  \"hswish\",  1 ],\n",
    "            [ 3,  184,  80,   False,  \"hswish\",  1 ],\n",
    "            [ 3,  480,  112,  True,   \"hswish\",  1 ],\n",
    "            [ 3,  672,  112,  True,   \"hswish\",  1 ],\n",
    "            [ 5,  672,  160,  True,   \"hswish\",  2 ],\n",
    "            [ 5,  960,  160,  True,   \"hswish\",  1 ],\n",
    "            [ 5,  960,  160,  True,   \"hswish\",  1 ],\n",
    "        ]\n",
    "\n",
    "        self.bneck = tf.keras.Sequential(name=\"Bneck\")\n",
    "        for idx, (k, exp, out, SE, NL, s) in enumerate(self.bneck_settings):\n",
    "            out_channels = _make_divisible(out * width_multiplier, divisible_by)\n",
    "            exp_channels = _make_divisible(exp * width_multiplier, divisible_by)\n",
    "\n",
    "            self.bneck.add(\n",
    "                LayerNamespaceWrapper(\n",
    "                    Bneck(\n",
    "                        out_channels=out_channels,\n",
    "                        exp_channels=exp_channels,\n",
    "                        kernel_size=k,\n",
    "                        stride=s,\n",
    "                        use_se=SE,\n",
    "                        act_layer=NL,\n",
    "                    ),\n",
    "                    name=f\"Bneck{idx}\")\n",
    "            )\n",
    "\n",
    "        # Last stage\n",
    "        penultimate_channels = _make_divisible(960 * width_multiplier, divisible_by)\n",
    "        last_channels = _make_divisible(1_280 * width_multiplier, divisible_by)\n",
    "\n",
    "        self.last_stage = LastStage(\n",
    "            penultimate_channels,\n",
    "            last_channels,\n",
    "            num_classes,\n",
    "            l2_reg=l2_reg,\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.first_layer(input)\n",
    "        x = self.bneck(x)\n",
    "        x = self.last_stage(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 666s 2s/step - loss: 0.7736 - accuracy: 0.7506 - f1_score: 0.7174 - precision: 0.7899 - recall: 0.6838 - val_loss: 2.4384 - val_accuracy: 0.0973 - val_f1_score: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 648s 2s/step - loss: 0.2842 - accuracy: 0.9311 - f1_score: 0.9310 - precision: 0.9406 - recall: 0.9217 - val_loss: 0.8900 - val_accuracy: 0.7152 - val_f1_score: 0.7132 - val_precision: 0.8584 - val_recall: 0.6116\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 649s 2s/step - loss: 0.2026 - accuracy: 0.9580 - f1_score: 0.9584 - precision: 0.9626 - recall: 0.9543 - val_loss: 0.3797 - val_accuracy: 0.9044 - val_f1_score: 0.9005 - val_precision: 0.9091 - val_recall: 0.8922\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 649s 2s/step - loss: 0.1592 - accuracy: 0.9748 - f1_score: 0.9739 - precision: 0.9762 - recall: 0.9716 - val_loss: 0.2316 - val_accuracy: 0.9495 - val_f1_score: 0.9485 - val_precision: 0.9558 - val_recall: 0.9415\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 649s 2s/step - loss: 0.1493 - accuracy: 0.9787 - f1_score: 0.9784 - precision: 0.9803 - recall: 0.9764 - val_loss: 0.2044 - val_accuracy: 0.9593 - val_f1_score: 0.9571 - val_precision: 0.9599 - val_recall: 0.9544\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 648s 2s/step - loss: 0.1194 - accuracy: 0.9875 - f1_score: 0.9874 - precision: 0.9884 - recall: 0.9864 - val_loss: 0.2115 - val_accuracy: 0.9572 - val_f1_score: 0.9565 - val_precision: 0.9587 - val_recall: 0.9545\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 649s 2s/step - loss: 0.1233 - accuracy: 0.9868 - f1_score: 0.9868 - precision: 0.9877 - recall: 0.9858 - val_loss: 0.2237 - val_accuracy: 0.9559 - val_f1_score: 0.9555 - val_precision: 0.9578 - val_recall: 0.9533\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 648s 2s/step - loss: 0.1026 - accuracy: 0.9941 - f1_score: 0.9932 - precision: 0.9938 - recall: 0.9926 - val_loss: 0.2740 - val_accuracy: 0.9542 - val_f1_score: 0.9536 - val_precision: 0.9550 - val_recall: 0.9523\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 649s 2s/step - loss: 0.1295 - accuracy: 0.9852 - f1_score: 0.9852 - precision: 0.9863 - recall: 0.9841 - val_loss: 0.1650 - val_accuracy: 0.9751 - val_f1_score: 0.9752 - val_precision: 0.9762 - val_recall: 0.9742\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 650s 2s/step - loss: 0.0960 - accuracy: 0.9968 - f1_score: 0.9968 - precision: 0.9971 - recall: 0.9965 - val_loss: 0.1608 - val_accuracy: 0.9758 - val_f1_score: 0.9754 - val_precision: 0.9764 - val_recall: 0.9744\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 649s 2s/step - loss: 0.0913 - accuracy: 0.9982 - f1_score: 0.9981 - precision: 0.9983 - recall: 0.9979 - val_loss: 0.1514 - val_accuracy: 0.9798 - val_f1_score: 0.9808 - val_precision: 0.9827 - val_recall: 0.9789\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 650s 2s/step - loss: 0.0913 - accuracy: 0.9978 - f1_score: 0.9975 - precision: 0.9975 - recall: 0.9974 - val_loss: 0.1514 - val_accuracy: 0.9811 - val_f1_score: 0.9813 - val_precision: 0.9832 - val_recall: 0.9794\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 649s 2s/step - loss: 0.0906 - accuracy: 0.9984 - f1_score: 0.9980 - precision: 0.9981 - recall: 0.9979 - val_loss: 0.1575 - val_accuracy: 0.9811 - val_f1_score: 0.9812 - val_precision: 0.9825 - val_recall: 0.9799\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 650s 2s/step - loss: 0.0928 - accuracy: 0.9974 - f1_score: 0.9973 - precision: 0.9976 - recall: 0.9970 - val_loss: 0.1538 - val_accuracy: 0.9811 - val_f1_score: 0.9814 - val_precision: 0.9827 - val_recall: 0.9802\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 650s 2s/step - loss: 0.0882 - accuracy: 0.9990 - f1_score: 0.9990 - precision: 0.9990 - recall: 0.9989 - val_loss: 0.1573 - val_accuracy: 0.9805 - val_f1_score: 0.9808 - val_precision: 0.9817 - val_recall: 0.9801\n"
     ]
    }
   ],
   "source": [
    "mobilenetv3large = build_mobilenetv3(\n",
    "    \"large\",\n",
    "    input_shape=input_shape+(3,),\n",
    "    num_classes=len(labels),\n",
    "    width_multiplier=1.0)\n",
    "\n",
    "mobilenetv3large.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_mobilenetv3large = mobilenetv3large.fit(train_batches,\n",
    "                             epochs=epoch,\n",
    "                             validation_data=val_batches,\n",
    "                             verbose=1,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 35s - loss: 0.1532 - accuracy: 0.9806 - f1_score: 0.9806 - precision: 0.9817 - recall: 0.9794 - 35s/epoch - 370ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = mobilenetv3large.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as Conv3x3_layer_call_fn, Conv3x3_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, BatchNormalization_layer_call_fn, BatchNormalization_layer_call_and_return_conditional_losses while saving (showing 5 of 847). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenetv3large_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenetv3large_no_weights\\assets\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA403C9700> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA471C26A0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA433243D0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA41B2BD00> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA5C2EB7C0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA59BB43D0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA70130760> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA46507FA0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA68D23190> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4D0563A0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA3F92FD30> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA40E6F4F0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001ED46D082E0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA44E371C0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4E63A3A0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4C1427F0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4180A160> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA422012E0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA50BD0370> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4E106640> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA57F0C0D0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA5A47AE80> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4C803C70> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA431B7190> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA75717BE0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA6C610460> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA47F7BB80> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA3E5802E0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA48AB8580> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA463D97C0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA45EE4970> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA4C7E3790> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4080CA00> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4D4F0220> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA70AB3460> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001ED485D5EB0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA3DF020D0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA597D4AF0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA6E8163D0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4EBFBAC0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001ED49610460> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001ED46BECE80> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001ED4599FCD0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4EFB2A90> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA5C2AF7C0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA68A03160> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA3EE402B0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA7173D130> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA5E464340> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA6B56D610> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA5E6FBD90> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA7A9E1370> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA6E6B3AC0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA4DE739D0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.GlobalAveragePooling2D object at 0x000001EA4EA4F5B0> has the same name 'GlobalAveragePooling2D' as a built-in Keras object. Consider renaming <class '__main__.GlobalAveragePooling2D'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.BatchNormalization object at 0x000001EA461CABB0> has the same name 'BatchNormalization' as a built-in Keras object. Consider renaming <class '__main__.BatchNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "mobilenetv3large.save(\"models/mobilenetv3large_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, Model\n",
    "\n",
    "class Fire(layers.Layer):\n",
    "    def __init__(self, out_channels, squeeze_channel):\n",
    "        super(Fire, self).__init__()\n",
    "        self.squeeze = Sequential([\n",
    "            layers.Conv2D(squeeze_channel, (1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.expand_1x1 = Sequential([\n",
    "            layers.Conv2D(int(out_channels / 2), (1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.expand_3x3 = Sequential([\n",
    "            layers.Conv2D(int(out_channels / 2), (3, 3), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.squeeze(x, training=training)\n",
    "        x = tf.concat([\n",
    "            self.expand_1x1(x, training=training),\n",
    "            self.expand_3x3(x, training=training)\n",
    "        ], -1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "class SqueezeNet(Model):\n",
    "    def __init__(self, num_classes, input_shape):\n",
    "        super(SqueezeNet, self).__init__()\n",
    "        self.stem = Sequential([\n",
    "            layers.Input(input_shape),\n",
    "            layers.Conv2D(96, (3, 3), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D((2, 2), strides=2)\n",
    "        ])\n",
    "        self.fire = Sequential([\n",
    "            Fire(128, 16),\n",
    "            Fire(128, 16),\n",
    "            Fire(256, 32),\n",
    "            Fire(256, 32),\n",
    "            Fire(384, 48),\n",
    "            Fire(384, 48),\n",
    "            Fire(512, 64),\n",
    "            Fire(512, 64)\n",
    "        ])\n",
    "        self.conv = layers.Conv2D(num_classes, 1)\n",
    "        self.ap = layers.AveragePooling2D((7, 7), strides=1)\n",
    "        self.mp = layers.MaxPooling2D()\n",
    "        self.flat = layers.Flatten()\n",
    "        self.fc = layers.Dense(num_classes, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.stem(inputs, training=training)\n",
    "        x = self.fire(x, training=training)\n",
    "        x = self.conv(x, training=training)\n",
    "        x = self.ap(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def model_squeezenet(num_classes, input_shape):\n",
    "    return SqueezeNet(num_classes, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 3752s 11s/step - loss: 0.7319 - accuracy: 0.7473 - f1_score: 0.7341 - precision: 0.7824 - recall: 0.6979 - val_loss: 6.9412 - val_accuracy: 0.2155 - val_f1_score: 0.2129 - val_precision: 0.2342 - val_recall: 0.1956\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 3672s 11s/step - loss: 0.2771 - accuracy: 0.9079 - f1_score: 0.9089 - precision: 0.9211 - recall: 0.8972 - val_loss: 0.3966 - val_accuracy: 0.8646 - val_f1_score: 0.8674 - val_precision: 0.8824 - val_recall: 0.8531\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 3678s 11s/step - loss: 0.1740 - accuracy: 0.9411 - f1_score: 0.9421 - precision: 0.9481 - recall: 0.9362 - val_loss: 0.4209 - val_accuracy: 0.8768 - val_f1_score: 0.8790 - val_precision: 0.8861 - val_recall: 0.8721\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 3680s 11s/step - loss: 0.1213 - accuracy: 0.9595 - f1_score: 0.9596 - precision: 0.9633 - recall: 0.9561 - val_loss: 0.2961 - val_accuracy: 0.9047 - val_f1_score: 0.9037 - val_precision: 0.9097 - val_recall: 0.8980\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 3688s 11s/step - loss: 0.0887 - accuracy: 0.9691 - f1_score: 0.9694 - precision: 0.9713 - recall: 0.9675 - val_loss: 0.2547 - val_accuracy: 0.9162 - val_f1_score: 0.9156 - val_precision: 0.9213 - val_recall: 0.9100\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 3709s 11s/step - loss: 0.0653 - accuracy: 0.9772 - f1_score: 0.9771 - precision: 0.9785 - recall: 0.9758 - val_loss: 0.6688 - val_accuracy: 0.8306 - val_f1_score: 0.8329 - val_precision: 0.8380 - val_recall: 0.8278\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 3712s 11s/step - loss: 0.0441 - accuracy: 0.9852 - f1_score: 0.9855 - precision: 0.9867 - recall: 0.9843 - val_loss: 0.1635 - val_accuracy: 0.9556 - val_f1_score: 0.9544 - val_precision: 0.9555 - val_recall: 0.9533\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 3705s 11s/step - loss: 0.0290 - accuracy: 0.9903 - f1_score: 0.9904 - precision: 0.9908 - recall: 0.9900 - val_loss: 0.1784 - val_accuracy: 0.9481 - val_f1_score: 0.9490 - val_precision: 0.9516 - val_recall: 0.9465\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 3703s 11s/step - loss: 0.0192 - accuracy: 0.9932 - f1_score: 0.9933 - precision: 0.9937 - recall: 0.9930 - val_loss: 0.1537 - val_accuracy: 0.9593 - val_f1_score: 0.9585 - val_precision: 0.9588 - val_recall: 0.9581\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 3706s 11s/step - loss: 0.0122 - accuracy: 0.9961 - f1_score: 0.9962 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.1269 - val_accuracy: 0.9687 - val_f1_score: 0.9689 - val_precision: 0.9692 - val_recall: 0.9686\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 3688s 11s/step - loss: 0.0145 - accuracy: 0.9947 - f1_score: 0.9947 - precision: 0.9949 - recall: 0.9944 - val_loss: 0.1374 - val_accuracy: 0.9633 - val_f1_score: 0.9622 - val_precision: 0.9635 - val_recall: 0.9610\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 3696s 11s/step - loss: 0.0083 - accuracy: 0.9972 - f1_score: 0.9973 - precision: 0.9973 - recall: 0.9972 - val_loss: 0.1338 - val_accuracy: 0.9670 - val_f1_score: 0.9669 - val_precision: 0.9681 - val_recall: 0.9658\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 3789s 12s/step - loss: 0.0038 - accuracy: 0.9988 - f1_score: 0.9988 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.1143 - val_accuracy: 0.9731 - val_f1_score: 0.9736 - val_precision: 0.9745 - val_recall: 0.9726\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 3687s 11s/step - loss: 0.0014 - accuracy: 0.9998 - f1_score: 0.9998 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.1056 - val_accuracy: 0.9771 - val_f1_score: 0.9772 - val_precision: 0.9776 - val_recall: 0.9769\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 3645s 11s/step - loss: 6.4729e-04 - accuracy: 1.0000 - f1_score: 0.9996 - precision: 0.9996 - recall: 0.9996 - val_loss: 0.1085 - val_accuracy: 0.9781 - val_f1_score: 0.9781 - val_precision: 0.9785 - val_recall: 0.9776\n"
     ]
    }
   ],
   "source": [
    "squeezenet = model_squeezenet(num_classes=len(labels), input_shape=input_shape+(3,))\n",
    "\n",
    "squeezenet.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_squeezenet = squeezenet.fit(train_batches,\n",
    "                             epochs=epoch,\n",
    "                             validation_data=val_batches,\n",
    "                             verbose=1,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 272s - loss: 0.1072 - accuracy: 0.9778 - f1_score: 0.9782 - precision: 0.9786 - recall: 0.9778 - 272s/epoch - 3s/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = squeezenet.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/squeezenet_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/squeezenet_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "squeezenet.save(\"models/squeezenet_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNetX002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 2594s 8s/step - loss: 1.4631 - accuracy: 0.5475 - f1_score: 0.2760 - precision: 0.1620 - recall: 0.9355 - val_loss: 0.5961 - val_accuracy: 0.8007 - val_f1_score: 0.3094 - val_precision: 0.1831 - val_recall: 0.9970\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2568s 8s/step - loss: 0.4055 - accuracy: 0.8595 - f1_score: 0.3243 - precision: 0.1936 - recall: 0.9983 - val_loss: 0.4570 - val_accuracy: 0.8623 - val_f1_score: 0.3275 - val_precision: 0.1959 - val_recall: 0.9987\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2566s 8s/step - loss: 0.1580 - accuracy: 0.9459 - f1_score: 0.3318 - precision: 0.1989 - recall: 0.9998 - val_loss: 0.2633 - val_accuracy: 0.9209 - val_f1_score: 0.3310 - val_precision: 0.1984 - val_recall: 0.9987\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2571s 8s/step - loss: 0.0500 - accuracy: 0.9841 - f1_score: 0.3360 - precision: 0.2020 - recall: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9303 - val_f1_score: 0.3395 - val_precision: 0.2045 - val_recall: 0.9983\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2660s 8s/step - loss: 0.0122 - accuracy: 0.9977 - f1_score: 0.3402 - precision: 0.2050 - recall: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9434 - val_f1_score: 0.3406 - val_precision: 0.2053 - val_recall: 0.9983\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2691s 8s/step - loss: 0.0034 - accuracy: 0.9999 - f1_score: 0.3401 - precision: 0.2049 - recall: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9438 - val_f1_score: 0.3403 - val_precision: 0.2051 - val_recall: 0.9983\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2617s 8s/step - loss: 0.0014 - accuracy: 1.0000 - f1_score: 0.3408 - precision: 0.2054 - recall: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9448 - val_f1_score: 0.3409 - val_precision: 0.2056 - val_recall: 0.9983\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2559s 8s/step - loss: 0.0011 - accuracy: 1.0000 - f1_score: 0.3412 - precision: 0.2057 - recall: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9444 - val_f1_score: 0.3413 - val_precision: 0.2059 - val_recall: 0.9983\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2556s 8s/step - loss: 9.3111e-04 - accuracy: 1.0000 - f1_score: 0.3416 - precision: 0.2060 - recall: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9451 - val_f1_score: 0.3418 - val_precision: 0.2062 - val_recall: 0.9983\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2557s 8s/step - loss: 8.2373e-04 - accuracy: 1.0000 - f1_score: 0.3418 - precision: 0.2062 - recall: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9451 - val_f1_score: 0.3422 - val_precision: 0.2065 - val_recall: 0.9983\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 2559s 8s/step - loss: 7.4601e-04 - accuracy: 1.0000 - f1_score: 0.3420 - precision: 0.2063 - recall: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9448 - val_f1_score: 0.3424 - val_precision: 0.2066 - val_recall: 0.9983\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 2569s 8s/step - loss: 6.8668e-04 - accuracy: 1.0000 - f1_score: 0.3423 - precision: 0.2065 - recall: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9448 - val_f1_score: 0.3426 - val_precision: 0.2068 - val_recall: 0.9983\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 2567s 8s/step - loss: 6.3956e-04 - accuracy: 1.0000 - f1_score: 0.3425 - precision: 0.2066 - recall: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9448 - val_f1_score: 0.3428 - val_precision: 0.2069 - val_recall: 0.9983\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 2628s 8s/step - loss: 6.0106e-04 - accuracy: 1.0000 - f1_score: 0.3426 - precision: 0.2067 - recall: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9448 - val_f1_score: 0.3429 - val_precision: 0.2070 - val_recall: 0.9983\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2584s 8s/step - loss: 5.6892e-04 - accuracy: 1.0000 - f1_score: 0.3427 - precision: 0.2068 - recall: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9448 - val_f1_score: 0.3431 - val_precision: 0.2072 - val_recall: 0.9983\n"
     ]
    }
   ],
   "source": [
    "model_regnetx002 = tf.keras.applications.regnet.RegNetX002(input_shape=input_shape+(3,), include_top=False, \n",
    "                                               include_preprocessing=False, weights=None)\n",
    "\n",
    "regnetx002 = keras.Sequential([\n",
    "    model_regnetx002,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "regnetx002.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_regnetx002 = regnetx002.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 69s - 69s/epoch - 726ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9461028192371476,\n",
       " 0.9461274661756428,\n",
       " 0.9461028192371476,\n",
       " 0.9460189873176599)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(regnetx002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 67s - loss: 0.2042 - accuracy: 0.9461 - f1_score: 0.3427 - precision: 0.2069 - recall: 0.9992 - 67s/epoch - 710ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = regnetx002.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 31). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnetx002_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnetx002_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "regnetx002.save(\"models/regnetx002_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNetX004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 2895s 9s/step - loss: 2.2041 - accuracy: 0.4637 - f1_score: 0.3123 - precision: 0.1945 - recall: 0.8118 - val_loss: 0.9117 - val_accuracy: 0.7902 - val_f1_score: 0.3749 - val_precision: 0.2316 - val_recall: 0.9840\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2842s 9s/step - loss: 0.5284 - accuracy: 0.8306 - f1_score: 0.3851 - precision: 0.2391 - recall: 0.9892 - val_loss: 0.4589 - val_accuracy: 0.8818 - val_f1_score: 0.3859 - val_precision: 0.2396 - val_recall: 0.9917\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2899s 9s/step - loss: 0.2619 - accuracy: 0.9185 - f1_score: 0.3862 - precision: 0.2396 - recall: 0.9960 - val_loss: 0.4180 - val_accuracy: 0.9054 - val_f1_score: 0.3844 - val_precision: 0.2384 - val_recall: 0.9924\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2901s 9s/step - loss: 0.1384 - accuracy: 0.9562 - f1_score: 0.3854 - precision: 0.2388 - recall: 0.9987 - val_loss: 0.4449 - val_accuracy: 0.9182 - val_f1_score: 0.3847 - val_precision: 0.2385 - val_recall: 0.9943\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2802s 9s/step - loss: 0.0622 - accuracy: 0.9819 - f1_score: 0.3824 - precision: 0.2365 - recall: 0.9994 - val_loss: 0.3824 - val_accuracy: 0.9215 - val_f1_score: 0.3766 - val_precision: 0.2323 - val_recall: 0.9950\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2781s 8s/step - loss: 0.0306 - accuracy: 0.9923 - f1_score: 0.3810 - precision: 0.2354 - recall: 0.9998 - val_loss: 0.3717 - val_accuracy: 0.9283 - val_f1_score: 0.3780 - val_precision: 0.2333 - val_recall: 0.9963\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2799s 9s/step - loss: 0.0129 - accuracy: 0.9968 - f1_score: 0.3779 - precision: 0.2330 - recall: 0.9998 - val_loss: 0.3544 - val_accuracy: 0.9296 - val_f1_score: 0.3792 - val_precision: 0.2342 - val_recall: 0.9957\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2897s 9s/step - loss: 0.0084 - accuracy: 0.9979 - f1_score: 0.3767 - precision: 0.2321 - recall: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9296 - val_f1_score: 0.3785 - val_precision: 0.2336 - val_recall: 0.9967\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2897s 9s/step - loss: 0.0041 - accuracy: 0.9992 - f1_score: 0.3763 - precision: 0.2318 - recall: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9354 - val_f1_score: 0.3771 - val_precision: 0.2326 - val_recall: 0.9967\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2909s 9s/step - loss: 0.0026 - accuracy: 0.9995 - f1_score: 0.3760 - precision: 0.2316 - recall: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9357 - val_f1_score: 0.3768 - val_precision: 0.2324 - val_recall: 0.9960\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 2895s 9s/step - loss: 0.0018 - accuracy: 0.9999 - f1_score: 0.3757 - precision: 0.2313 - recall: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9350 - val_f1_score: 0.3763 - val_precision: 0.2320 - val_recall: 0.9967\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 2837s 9s/step - loss: 0.0013 - accuracy: 1.0000 - f1_score: 0.3759 - precision: 0.2314 - recall: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9364 - val_f1_score: 0.3765 - val_precision: 0.2321 - val_recall: 0.9970\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 2764s 8s/step - loss: 9.9527e-04 - accuracy: 1.0000 - f1_score: 0.3758 - precision: 0.2314 - recall: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9370 - val_f1_score: 0.3760 - val_precision: 0.2317 - val_recall: 0.9967\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 2771s 8s/step - loss: 8.0483e-04 - accuracy: 1.0000 - f1_score: 0.3757 - precision: 0.2313 - recall: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9377 - val_f1_score: 0.3760 - val_precision: 0.2317 - val_recall: 0.9967\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2768s 8s/step - loss: 7.0741e-04 - accuracy: 1.0000 - f1_score: 0.3756 - precision: 0.2313 - recall: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9384 - val_f1_score: 0.3761 - val_precision: 0.2318 - val_recall: 0.9967\n"
     ]
    }
   ],
   "source": [
    "model_regnetx004 = tf.keras.applications.regnet.RegNetX004(input_shape=input_shape+(3,), include_top=False, \n",
    "                                               include_preprocessing=False, weights=None)\n",
    "\n",
    "regnetx004 = keras.Sequential([\n",
    "    model_regnetx004,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "regnetx004.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_regnetx004 = regnetx004.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 94s - 94s/epoch - 984ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9383084577114428,\n",
       " 0.9388423257207839,\n",
       " 0.9383084577114428,\n",
       " 0.9382406773344414)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(regnetx004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 91s - loss: 0.3150 - accuracy: 0.9383 - f1_score: 0.3774 - precision: 0.2328 - recall: 0.9974 - 91s/epoch - 962ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = regnetx004.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 49). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnetx004_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnetx004_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "regnetx004.save(\"models/regnetx004_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNetX006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 2253s 7s/step - loss: 1.9946 - accuracy: 0.4800 - f1_score: 0.3038 - precision: 0.1875 - recall: 0.8228 - val_loss: 0.7408 - val_accuracy: 0.7859 - val_f1_score: 0.3614 - val_precision: 0.2211 - val_recall: 0.9894\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2244s 7s/step - loss: 0.4596 - accuracy: 0.8571 - f1_score: 0.3737 - precision: 0.2302 - recall: 0.9937 - val_loss: 0.5464 - val_accuracy: 0.8694 - val_f1_score: 0.3627 - val_precision: 0.2219 - val_recall: 0.9940\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2251s 7s/step - loss: 0.2049 - accuracy: 0.9351 - f1_score: 0.3756 - precision: 0.2314 - recall: 0.9985 - val_loss: 0.3008 - val_accuracy: 0.9138 - val_f1_score: 0.3705 - val_precision: 0.2275 - val_recall: 0.9977\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2274s 7s/step - loss: 0.0908 - accuracy: 0.9726 - f1_score: 0.3744 - precision: 0.2304 - recall: 0.9996 - val_loss: 0.2410 - val_accuracy: 0.9354 - val_f1_score: 0.3714 - val_precision: 0.2282 - val_recall: 0.9973\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2350s 7s/step - loss: 0.0381 - accuracy: 0.9893 - f1_score: 0.3742 - precision: 0.2302 - recall: 0.9998 - val_loss: 0.2027 - val_accuracy: 0.9468 - val_f1_score: 0.3713 - val_precision: 0.2281 - val_recall: 0.9980\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2252s 7s/step - loss: 0.0129 - accuracy: 0.9968 - f1_score: 0.3728 - precision: 0.2291 - recall: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9444 - val_f1_score: 0.3727 - val_precision: 0.2292 - val_recall: 0.9983\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2238s 7s/step - loss: 0.0044 - accuracy: 0.9993 - f1_score: 0.3732 - precision: 0.2295 - recall: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9519 - val_f1_score: 0.3727 - val_precision: 0.2292 - val_recall: 0.9983\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2236s 7s/step - loss: 0.0014 - accuracy: 1.0000 - f1_score: 0.3727 - precision: 0.2291 - recall: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9529 - val_f1_score: 0.3720 - val_precision: 0.2286 - val_recall: 0.9980\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2200s 7s/step - loss: 0.0011 - accuracy: 0.9999 - f1_score: 0.3727 - precision: 0.2291 - recall: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9535 - val_f1_score: 0.3725 - val_precision: 0.2290 - val_recall: 0.9980\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2191s 7s/step - loss: 6.6100e-04 - accuracy: 1.0000 - f1_score: 0.3725 - precision: 0.2289 - recall: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9535 - val_f1_score: 0.3727 - val_precision: 0.2292 - val_recall: 0.9980\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 2187s 7s/step - loss: 5.6040e-04 - accuracy: 1.0000 - f1_score: 0.3724 - precision: 0.2289 - recall: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9535 - val_f1_score: 0.3727 - val_precision: 0.2292 - val_recall: 0.9980\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 2136s 6s/step - loss: 4.9911e-04 - accuracy: 1.0000 - f1_score: 0.3725 - precision: 0.2289 - recall: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9539 - val_f1_score: 0.3728 - val_precision: 0.2293 - val_recall: 0.9980\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 2102s 6s/step - loss: 4.5475e-04 - accuracy: 1.0000 - f1_score: 0.3725 - precision: 0.2289 - recall: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9539 - val_f1_score: 0.3728 - val_precision: 0.2292 - val_recall: 0.9980\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 2122s 6s/step - loss: 4.2039e-04 - accuracy: 1.0000 - f1_score: 0.3725 - precision: 0.2289 - recall: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9539 - val_f1_score: 0.3729 - val_precision: 0.2293 - val_recall: 0.9980\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2125s 6s/step - loss: 3.9280e-04 - accuracy: 1.0000 - f1_score: 0.3726 - precision: 0.2290 - recall: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9539 - val_f1_score: 0.3729 - val_precision: 0.2293 - val_recall: 0.9980\n"
     ]
    }
   ],
   "source": [
    "model_regnetx006 = tf.keras.applications.regnet.RegNetX006(input_shape=input_shape+(3,), include_top=False, \n",
    "                                               include_preprocessing=False, weights=None)\n",
    "\n",
    "regnetx006 = keras.Sequential([\n",
    "    model_regnetx006,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "regnetx006.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_regnetx006 = regnetx006.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 53s - 53s/epoch - 560ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9504145936981758,\n",
       " 0.9505773683445093,\n",
       " 0.9504145936981758,\n",
       " 0.9504066614868186)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(regnetx006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 52s - loss: 0.2239 - accuracy: 0.9504 - f1_score: 0.3734 - precision: 0.2297 - recall: 0.9979 - 52s/epoch - 551ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = regnetx006.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 37). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnetx006_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnetx006_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "regnetx006.save(\"models/regnetx006_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNetY002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 2515s 8s/step - loss: 1.5274 - accuracy: 0.5313 - f1_score: 0.3477 - precision: 0.2251 - recall: 0.7882 - val_loss: 0.7992 - val_accuracy: 0.7593 - val_f1_score: 0.3934 - val_precision: 0.2462 - val_recall: 0.9794\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 2563s 8s/step - loss: 0.4438 - accuracy: 0.8515 - f1_score: 0.4162 - precision: 0.2635 - recall: 0.9909 - val_loss: 0.3950 - val_accuracy: 0.8842 - val_f1_score: 0.4170 - val_precision: 0.2640 - val_recall: 0.9930\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 2592s 8s/step - loss: 0.2030 - accuracy: 0.9291 - f1_score: 0.4217 - precision: 0.2674 - recall: 0.9984 - val_loss: 0.3683 - val_accuracy: 0.8990 - val_f1_score: 0.4158 - val_precision: 0.2629 - val_recall: 0.9947\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 2568s 8s/step - loss: 0.0879 - accuracy: 0.9695 - f1_score: 0.4225 - precision: 0.2679 - recall: 0.9997 - val_loss: 0.2952 - val_accuracy: 0.9098 - val_f1_score: 0.4209 - val_precision: 0.2668 - val_recall: 0.9970\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 2566s 8s/step - loss: 0.0308 - accuracy: 0.9912 - f1_score: 0.4205 - precision: 0.2663 - recall: 0.9999 - val_loss: 0.2297 - val_accuracy: 0.9360 - val_f1_score: 0.4204 - val_precision: 0.2664 - val_recall: 0.9973\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 2567s 8s/step - loss: 0.0071 - accuracy: 0.9995 - f1_score: 0.4173 - precision: 0.2637 - recall: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9401 - val_f1_score: 0.4162 - val_precision: 0.2630 - val_recall: 0.9980\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 2568s 8s/step - loss: 0.0019 - accuracy: 1.0000 - f1_score: 0.4154 - precision: 0.2622 - recall: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9407 - val_f1_score: 0.4165 - val_precision: 0.2632 - val_recall: 0.9977\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 2574s 8s/step - loss: 0.0012 - accuracy: 1.0000 - f1_score: 0.4146 - precision: 0.2616 - recall: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9397 - val_f1_score: 0.4164 - val_precision: 0.2631 - val_recall: 0.9977\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 2573s 8s/step - loss: 9.4352e-04 - accuracy: 1.0000 - f1_score: 0.4142 - precision: 0.2612 - recall: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9397 - val_f1_score: 0.4160 - val_precision: 0.2628 - val_recall: 0.9977\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 2577s 8s/step - loss: 8.1223e-04 - accuracy: 1.0000 - f1_score: 0.4137 - precision: 0.2609 - recall: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9411 - val_f1_score: 0.4159 - val_precision: 0.2628 - val_recall: 0.9977\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 2620s 8s/step - loss: 7.2197e-04 - accuracy: 1.0000 - f1_score: 0.4135 - precision: 0.2607 - recall: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9411 - val_f1_score: 0.4160 - val_precision: 0.2628 - val_recall: 0.9977\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 2687s 8s/step - loss: 6.5507e-04 - accuracy: 1.0000 - f1_score: 0.4133 - precision: 0.2605 - recall: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9421 - val_f1_score: 0.4159 - val_precision: 0.2628 - val_recall: 0.9977\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 2695s 8s/step - loss: 6.0327e-04 - accuracy: 1.0000 - f1_score: 0.4131 - precision: 0.2604 - recall: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9418 - val_f1_score: 0.4155 - val_precision: 0.2624 - val_recall: 0.9977\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 2683s 8s/step - loss: 5.6173e-04 - accuracy: 1.0000 - f1_score: 0.4130 - precision: 0.2603 - recall: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9418 - val_f1_score: 0.4153 - val_precision: 0.2623 - val_recall: 0.9977\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 2577s 8s/step - loss: 5.2763e-04 - accuracy: 1.0000 - f1_score: 0.4128 - precision: 0.2601 - recall: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9418 - val_f1_score: 0.4155 - val_precision: 0.2624 - val_recall: 0.9977\n"
     ]
    }
   ],
   "source": [
    "model_regnety002 = tf.keras.applications.regnet.RegNetY002(input_shape=input_shape+(3,), include_top=False, \n",
    "                                               include_preprocessing=False, weights=None)\n",
    "\n",
    "regnety002 = keras.Sequential([\n",
    "    model_regnety002,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "regnety002.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_regnety002 = regnety002.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 72s - 72s/epoch - 753ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9442786069651742,\n",
       " 0.9443658501027206,\n",
       " 0.9442786069651742,\n",
       " 0.9441757452932362)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(regnety002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 70s - loss: 0.2258 - accuracy: 0.9443 - f1_score: 0.4131 - precision: 0.2605 - recall: 0.9985 - 70s/epoch - 735ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = regnety002.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnety002_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnety002_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "regnety002.save(\"models/regnety002_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNetY004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 3648s 11s/step - loss: 1.9377 - accuracy: 0.4083 - f1_score: 0.2810 - precision: 0.1736 - recall: 0.7624 - val_loss: 0.8156 - val_accuracy: 0.7508 - val_f1_score: 0.3560 - val_precision: 0.2172 - val_recall: 0.9864\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 3635s 11s/step - loss: 0.5291 - accuracy: 0.8297 - f1_score: 0.3691 - precision: 0.2269 - recall: 0.9888 - val_loss: 0.5034 - val_accuracy: 0.8808 - val_f1_score: 0.3661 - val_precision: 0.2244 - val_recall: 0.9934\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 3629s 11s/step - loss: 0.2501 - accuracy: 0.9238 - f1_score: 0.3757 - precision: 0.2315 - recall: 0.9961 - val_loss: 0.3595 - val_accuracy: 0.9084 - val_f1_score: 0.3740 - val_precision: 0.2303 - val_recall: 0.9953\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 3628s 11s/step - loss: 0.1070 - accuracy: 0.9681 - f1_score: 0.3732 - precision: 0.2295 - recall: 0.9987 - val_loss: 0.2777 - val_accuracy: 0.9256 - val_f1_score: 0.3712 - val_precision: 0.2280 - val_recall: 0.9977\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 3631s 11s/step - loss: 0.0637 - accuracy: 0.9806 - f1_score: 0.3728 - precision: 0.2292 - recall: 0.9995 - val_loss: 0.2785 - val_accuracy: 0.9283 - val_f1_score: 0.3693 - val_precision: 0.2266 - val_recall: 0.9980\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 3627s 11s/step - loss: 0.0337 - accuracy: 0.9900 - f1_score: 0.3726 - precision: 0.2290 - recall: 0.9999 - val_loss: 0.2697 - val_accuracy: 0.9300 - val_f1_score: 0.3722 - val_precision: 0.2287 - val_recall: 0.9987\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 3629s 11s/step - loss: 0.0285 - accuracy: 0.9921 - f1_score: 0.3751 - precision: 0.2309 - recall: 0.9999 - val_loss: 0.2658 - val_accuracy: 0.9330 - val_f1_score: 0.3734 - val_precision: 0.2296 - val_recall: 0.9990\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 3631s 11s/step - loss: 0.0154 - accuracy: 0.9959 - f1_score: 0.3743 - precision: 0.2303 - recall: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9354 - val_f1_score: 0.3725 - val_precision: 0.2290 - val_recall: 0.9983\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 3632s 11s/step - loss: 0.0062 - accuracy: 0.9985 - f1_score: 0.3730 - precision: 0.2292 - recall: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9360 - val_f1_score: 0.3728 - val_precision: 0.2292 - val_recall: 0.9983\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 3636s 11s/step - loss: 0.0026 - accuracy: 0.9996 - f1_score: 0.3727 - precision: 0.2291 - recall: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9357 - val_f1_score: 0.3720 - val_precision: 0.2286 - val_recall: 0.9983\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 3633s 11s/step - loss: 0.0013 - accuracy: 1.0000 - f1_score: 0.3726 - precision: 0.2290 - recall: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9364 - val_f1_score: 0.3715 - val_precision: 0.2283 - val_recall: 0.9983\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 3635s 11s/step - loss: 9.3691e-04 - accuracy: 1.0000 - f1_score: 0.3724 - precision: 0.2288 - recall: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9364 - val_f1_score: 0.3716 - val_precision: 0.2283 - val_recall: 0.9983\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 3633s 11s/step - loss: 7.4684e-04 - accuracy: 1.0000 - f1_score: 0.3724 - precision: 0.2288 - recall: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9370 - val_f1_score: 0.3714 - val_precision: 0.2281 - val_recall: 0.9983\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 3633s 11s/step - loss: 6.4954e-04 - accuracy: 1.0000 - f1_score: 0.3722 - precision: 0.2287 - recall: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9370 - val_f1_score: 0.3715 - val_precision: 0.2282 - val_recall: 0.9983\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 3635s 11s/step - loss: 5.8252e-04 - accuracy: 1.0000 - f1_score: 0.3721 - precision: 0.2286 - recall: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9370 - val_f1_score: 0.3714 - val_precision: 0.2281 - val_recall: 0.9983\n"
     ]
    }
   ],
   "source": [
    "model_regnety004 = tf.keras.applications.regnet.RegNetY004(input_shape=input_shape+(3,), include_top=False, \n",
    "                                               include_preprocessing=False, weights=None)\n",
    "\n",
    "regnety004 = keras.Sequential([\n",
    "    model_regnety004,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "regnety004.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_regnety004 = regnety004.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 19s - 19s/epoch - 195ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9321724709784411,\n",
       " 0.9333378687274676,\n",
       " 0.9321724709784411,\n",
       " 0.9320707801421217)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(regnety004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 16s - loss: 0.3048 - accuracy: 0.9322 - f1_score: 0.3705 - precision: 0.2276 - recall: 0.9969 - 16s/epoch - 166ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = regnety004.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 69). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnety004_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnety004_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "regnety004.save(\"models/regnety004_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNetY006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 3322s 10s/step - loss: 1.5604 - accuracy: 0.5128 - f1_score: 0.3116 - precision: 0.1922 - recall: 0.8334 - val_loss: 1.1283 - val_accuracy: 0.7508 - val_f1_score: 0.3458 - val_precision: 0.2096 - val_recall: 0.9879\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 3291s 10s/step - loss: 0.4276 - accuracy: 0.8560 - f1_score: 0.3662 - precision: 0.2244 - recall: 0.9956 - val_loss: 0.3599 - val_accuracy: 0.8734 - val_f1_score: 0.3654 - val_precision: 0.2238 - val_recall: 0.9950\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 3290s 10s/step - loss: 0.1925 - accuracy: 0.9350 - f1_score: 0.3738 - precision: 0.2299 - recall: 0.9991 - val_loss: 0.2352 - val_accuracy: 0.9276 - val_f1_score: 0.3733 - val_precision: 0.2296 - val_recall: 0.9980\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 3285s 10s/step - loss: 0.0899 - accuracy: 0.9693 - f1_score: 0.3794 - precision: 0.2342 - recall: 0.9998 - val_loss: 0.2133 - val_accuracy: 0.9401 - val_f1_score: 0.3825 - val_precision: 0.2367 - val_recall: 0.9977\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 3286s 10s/step - loss: 0.0433 - accuracy: 0.9870 - f1_score: 0.3811 - precision: 0.2355 - recall: 0.9999 - val_loss: 0.1830 - val_accuracy: 0.9488 - val_f1_score: 0.3796 - val_precision: 0.2344 - val_recall: 0.9977\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 3281s 10s/step - loss: 0.0112 - accuracy: 0.9977 - f1_score: 0.3807 - precision: 0.2351 - recall: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9515 - val_f1_score: 0.3795 - val_precision: 0.2345 - val_recall: 0.9963\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 3288s 10s/step - loss: 0.0032 - accuracy: 0.9997 - f1_score: 0.3801 - precision: 0.2347 - recall: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9515 - val_f1_score: 0.3810 - val_precision: 0.2355 - val_recall: 0.9967\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 3299s 10s/step - loss: 0.0012 - accuracy: 1.0000 - f1_score: 0.3793 - precision: 0.2341 - recall: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9542 - val_f1_score: 0.3797 - val_precision: 0.2345 - val_recall: 0.9963\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 3291s 10s/step - loss: 7.7272e-04 - accuracy: 1.0000 - f1_score: 0.3792 - precision: 0.2340 - recall: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9549 - val_f1_score: 0.3797 - val_precision: 0.2346 - val_recall: 0.9963\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 3289s 10s/step - loss: 6.3172e-04 - accuracy: 1.0000 - f1_score: 0.3790 - precision: 0.2338 - recall: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9552 - val_f1_score: 0.3796 - val_precision: 0.2345 - val_recall: 0.9960\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 3288s 10s/step - loss: 5.5123e-04 - accuracy: 1.0000 - f1_score: 0.3788 - precision: 0.2337 - recall: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9552 - val_f1_score: 0.3796 - val_precision: 0.2346 - val_recall: 0.9957\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 3290s 10s/step - loss: 4.9466e-04 - accuracy: 1.0000 - f1_score: 0.3788 - precision: 0.2337 - recall: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9552 - val_f1_score: 0.3794 - val_precision: 0.2344 - val_recall: 0.9957\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 3287s 10s/step - loss: 4.5213e-04 - accuracy: 1.0000 - f1_score: 0.3787 - precision: 0.2336 - recall: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9552 - val_f1_score: 0.3793 - val_precision: 0.2343 - val_recall: 0.9957\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 3301s 10s/step - loss: 4.1882e-04 - accuracy: 1.0000 - f1_score: 0.3786 - precision: 0.2336 - recall: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9552 - val_f1_score: 0.3794 - val_precision: 0.2344 - val_recall: 0.9957\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 3295s 10s/step - loss: 3.9189e-04 - accuracy: 1.0000 - f1_score: 0.3786 - precision: 0.2335 - recall: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9556 - val_f1_score: 0.3795 - val_precision: 0.2345 - val_recall: 0.9957\n"
     ]
    }
   ],
   "source": [
    "model_regnety006 = tf.keras.applications.regnet.RegNetY006(input_shape=input_shape+(3,), include_top=False, \n",
    "                                               include_preprocessing=False, weights=None)\n",
    "\n",
    "regnety006 = keras.Sequential([\n",
    "    model_regnety006,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(labels))                \n",
    "])\n",
    "\n",
    "regnety006.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_regnety006 = regnety006.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 79s - 79s/epoch - 829ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9587064676616915,\n",
       " 0.9587201360290123,\n",
       " 0.9587064676616915,\n",
       " 0.9586563954167945)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calc(regnety006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 77s - loss: 0.1583 - accuracy: 0.9587 - f1_score: 0.3795 - precision: 0.2342 - recall: 0.9990 - 77s/epoch - 811ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = regnety006.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnety006_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/regnety006_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "regnety006.save(\"models/regnety006_no_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShuffleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Machine-Learning-Tokyo/CNN-Architectures/tree/master/Implementations/ShuffleNet\n",
    "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, \\\n",
    "     Dense, Concatenate, Add, ReLU, BatchNormalization, AvgPool2D, \\\n",
    "     MaxPool2D, GlobalAvgPool2D, Reshape, Permute, Lambda\n",
    "    \n",
    "def stage(x, channels, repetitions, groups):\n",
    "    x = shufflenet_block(x, channels=channels, strides=2, groups=groups)\n",
    "    for i in range(repetitions):\n",
    "        x = shufflenet_block(x, channels=channels, strides=1, groups=groups)\n",
    "    return x\n",
    "\n",
    "\n",
    "def shufflenet_block(tensor, channels, strides, groups):\n",
    "    x = gconv(tensor, channels=channels // 4, groups=groups)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = channel_shuffle(x, groups)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    if strides == 2:\n",
    "        channels = channels - tensor.get_shape().as_list()[-1]\n",
    "    x = gconv(x, channels=channels, groups=groups)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    if strides == 1:\n",
    "        x = Add()([tensor, x])\n",
    "    else:\n",
    "        avg = AvgPool2D(pool_size=3, strides=2, padding='same')(tensor)\n",
    "        x = Concatenate()([avg, x])\n",
    "\n",
    "    output = ReLU()(x)\n",
    "    return output\n",
    "\n",
    "def gconv(tensor, channels, groups):\n",
    "    input_ch = tensor.get_shape().as_list()[-1]\n",
    "    group_ch = input_ch // groups\n",
    "    output_ch = channels // groups\n",
    "    groups_list = []\n",
    "\n",
    "    for i in range(groups):\n",
    "        # group_tensor = tensor[:, :, :, i * group_ch: (i+1) * group_ch]\n",
    "        group_tensor = Lambda(lambda x: x[:, :, :, i * group_ch: (i+1) * group_ch])(tensor)\n",
    "        group_tensor = Conv2D(output_ch, 1)(group_tensor)\n",
    "        groups_list.append(group_tensor)\n",
    "\n",
    "    output = Concatenate()(groups_list)\n",
    "    return output\n",
    "\n",
    "\n",
    "def channel_shuffle(x, groups):  \n",
    "    _, width, height, channels = x.get_shape().as_list()\n",
    "    group_ch = channels // groups\n",
    "\n",
    "    x = Reshape([width, height, group_ch, groups])(x)\n",
    "    x = Permute([1, 2, 4, 3])(x)\n",
    "    x = Reshape([width, height, channels])(x)\n",
    "    return x\n",
    "\n",
    "def shufflenet_model(input_shape, num_classes):\n",
    "\n",
    "    input = Input(input_shape)\n",
    "    x = Conv2D(filters=24, kernel_size=3, strides=2, padding='same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    repetitions = 3, 7, 3\n",
    "    initial_channels = 384\n",
    "    groups = 8\n",
    "\n",
    "    for i, reps in enumerate(repetitions):\n",
    "        channels = initial_channels * (2**i)\n",
    "        x = stage(x, channels, reps, groups)\n",
    "\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    from tensorflow.keras import Model\n",
    "    model = Model(input, output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 504s 1s/step - loss: 4.8235 - accuracy: 0.2711 - f1_score: 0.1079 - precision: 0.3357 - recall: 0.0713 - val_loss: 2.0272 - val_accuracy: 0.3694 - val_f1_score: 0.1028 - val_precision: 0.5916 - val_recall: 0.0570\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 463s 1s/step - loss: 1.1641 - accuracy: 0.6253 - f1_score: 0.5669 - precision: 0.7329 - recall: 0.4734 - val_loss: 0.8652 - val_accuracy: 0.7081 - val_f1_score: 0.6953 - val_precision: 0.7820 - val_recall: 0.6268\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 462s 1s/step - loss: 0.7466 - accuracy: 0.7589 - f1_score: 0.7503 - precision: 0.8121 - recall: 0.6986 - val_loss: 0.6060 - val_accuracy: 0.7939 - val_f1_score: 0.7950 - val_precision: 0.8351 - val_recall: 0.7591\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 462s 1s/step - loss: 0.5645 - accuracy: 0.8143 - f1_score: 0.8117 - precision: 0.8479 - recall: 0.7792 - val_loss: 0.5062 - val_accuracy: 0.8411 - val_f1_score: 0.8387 - val_precision: 0.8627 - val_recall: 0.8164\n",
      "Epoch 5/15\n",
      "329/329 [==============================] - 460s 1s/step - loss: 0.4690 - accuracy: 0.8442 - f1_score: 0.8430 - precision: 0.8705 - recall: 0.8175 - val_loss: 0.7372 - val_accuracy: 0.7690 - val_f1_score: 0.7661 - val_precision: 0.7886 - val_recall: 0.7451\n",
      "Epoch 6/15\n",
      "329/329 [==============================] - 459s 1s/step - loss: 0.4855 - accuracy: 0.8320 - f1_score: 0.8307 - precision: 0.8590 - recall: 0.8049 - val_loss: 0.5081 - val_accuracy: 0.8737 - val_f1_score: 0.8735 - val_precision: 0.8890 - val_recall: 0.8588\n",
      "Epoch 7/15\n",
      "329/329 [==============================] - 459s 1s/step - loss: 0.3604 - accuracy: 0.8785 - f1_score: 0.8773 - precision: 0.8967 - recall: 0.8590 - val_loss: 0.3673 - val_accuracy: 0.8758 - val_f1_score: 0.8751 - val_precision: 0.8899 - val_recall: 0.8609\n",
      "Epoch 8/15\n",
      "329/329 [==============================] - 459s 1s/step - loss: 0.3040 - accuracy: 0.8950 - f1_score: 0.8958 - precision: 0.9112 - recall: 0.8811 - val_loss: 0.4326 - val_accuracy: 0.8912 - val_f1_score: 0.8934 - val_precision: 0.9039 - val_recall: 0.8833\n",
      "Epoch 9/15\n",
      "329/329 [==============================] - 460s 1s/step - loss: 0.2947 - accuracy: 0.8975 - f1_score: 0.8977 - precision: 0.9117 - recall: 0.8844 - val_loss: 0.3181 - val_accuracy: 0.9010 - val_f1_score: 0.9001 - val_precision: 0.9116 - val_recall: 0.8890\n",
      "Epoch 10/15\n",
      "329/329 [==============================] - 459s 1s/step - loss: 0.2621 - accuracy: 0.9104 - f1_score: 0.9105 - precision: 0.9221 - recall: 0.8994 - val_loss: 0.3307 - val_accuracy: 0.8939 - val_f1_score: 0.8944 - val_precision: 0.9032 - val_recall: 0.8858\n",
      "Epoch 11/15\n",
      "329/329 [==============================] - 459s 1s/step - loss: 0.2401 - accuracy: 0.9186 - f1_score: 0.9160 - precision: 0.9264 - recall: 0.9059 - val_loss: 0.3146 - val_accuracy: 0.9098 - val_f1_score: 0.9119 - val_precision: 0.9194 - val_recall: 0.9046\n",
      "Epoch 12/15\n",
      "329/329 [==============================] - 460s 1s/step - loss: 0.2184 - accuracy: 0.9242 - f1_score: 0.9244 - precision: 0.9337 - recall: 0.9154 - val_loss: 0.3108 - val_accuracy: 0.8997 - val_f1_score: 0.9008 - val_precision: 0.9072 - val_recall: 0.8947\n",
      "Epoch 13/15\n",
      "329/329 [==============================] - 459s 1s/step - loss: 0.1992 - accuracy: 0.9301 - f1_score: 0.9303 - precision: 0.9383 - recall: 0.9225 - val_loss: 0.3516 - val_accuracy: 0.9114 - val_f1_score: 0.9107 - val_precision: 0.9185 - val_recall: 0.9032\n",
      "Epoch 14/15\n",
      "329/329 [==============================] - 459s 1s/step - loss: 0.1957 - accuracy: 0.9312 - f1_score: 0.9311 - precision: 0.9403 - recall: 0.9223 - val_loss: 0.2477 - val_accuracy: 0.9259 - val_f1_score: 0.9268 - val_precision: 0.9338 - val_recall: 0.9201\n",
      "Epoch 15/15\n",
      "329/329 [==============================] - 460s 1s/step - loss: 0.1775 - accuracy: 0.9392 - f1_score: 0.9383 - precision: 0.9454 - recall: 0.9314 - val_loss: 0.3192 - val_accuracy: 0.9168 - val_f1_score: 0.9174 - val_precision: 0.9227 - val_recall: 0.9123\n"
     ]
    }
   ],
   "source": [
    "shufflenet = shufflenet_model(input_shape+(3,), len(labels))\n",
    "\n",
    "shufflenet.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "history_shufflenet = shufflenet.fit(train_batches,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=val_batches, \n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 - 29s - loss: 0.3032 - accuracy: 0.9182 - f1_score: 0.9186 - precision: 0.9259 - recall: 0.9114 - 29s/epoch - 303ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_f1, test_prec, test_rec = shufflenet.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 273). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/shufflenet_no_weights\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/shufflenet_no_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "shufflenet.save(\"models/shufflenet_no_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
