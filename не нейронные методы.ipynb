{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UdsrHlDFR8EB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEERbDXjSmCh",
    "outputId": "a6ed1555-8301-45fa-b01a-082036833e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 30000\n"
     ]
    }
   ],
   "source": [
    "ds_dir = '/arch/mnist_data'\n",
    "filenames = []\n",
    "\n",
    "for root, dirs, files in os.walk(ds_dir):\n",
    "    for file in files:\n",
    "        filenames.append(os.path.join(root,file))\n",
    "filenames = [re.sub(r'(\\\\)', '/', name) for name in filenames[1:]]\n",
    "\n",
    "samples_number = len(filenames)\n",
    "print('Total number of samples:', samples_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbE_0KGkS4xo",
    "outputId": "aacae527-a942-4555-90dd-e9c2b3e6efe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size 21000\n",
      "Test data size 9000\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "train_files,test_files = train_test_split(filenames, test_size=0.3, shuffle=True)\n",
    "\n",
    "print('Training data size', len(train_files))\n",
    "print('Test data size', len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_24GUB7FeV16"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    label = re.findall(r'/([0-9])_', file_path)[0]\n",
    "    label = np.argmax(label == labels)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128,44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ct0Q8zUlfj4w"
   },
   "outputs": [],
   "source": [
    "def get_ms(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    ms = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=512)\n",
    "    ms = np.resize(ms, input_shape)\n",
    "    \n",
    "    ms = np.log(ms + 1e-9)\n",
    "    ms = librosa.util.normalize(ms)\n",
    "    return ms.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4LmQusI6cFUm"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(files):\n",
    "    output_labels = np.array([get_label(file) for file in files])\n",
    "    output_ms = np.array([get_ms(file) for file in files])\n",
    "    return output_ms, output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uQBzV_u_j3As",
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_ms,train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test_ms,test_labels \u001b[38;5;241m=\u001b[39m preprocess_dataset(test_files)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mpreprocess_dataset\u001b[1;34m(files)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_dataset\u001b[39m(files):\n\u001b[0;32m      2\u001b[0m     output_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_label(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files])\n\u001b[1;32m----> 3\u001b[0m     output_ms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_ms(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_ms, output_labels\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_dataset\u001b[39m(files):\n\u001b[0;32m      2\u001b[0m     output_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_label(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files])\n\u001b[1;32m----> 3\u001b[0m     output_ms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_ms, output_labels\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mget_ms\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ms\u001b[39m(file_path):\n\u001b[1;32m----> 3\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     ms \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmelspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr,n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m      5\u001b[0m     ms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresize(ms, input_shape)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:179\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    176\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     sr \u001b[38;5;241m=\u001b[39m sr_native\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:647\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m soxr\u001b[38;5;241m.\u001b[39mresample(y\u001b[38;5;241m.\u001b[39mT, orig_sr, target_sr, quality\u001b[38;5;241m=\u001b[39mres_type)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mresampy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[0;32m    650\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mfix_length(y_hat, size\u001b[38;5;241m=\u001b[39mn_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\resampy\\core.py:168\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         resample_f_s(\n\u001b[0;32m    159\u001b[0m             x\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis),\n\u001b[0;32m    160\u001b[0m             t_out,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m             y\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis),\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[43mresample_f_s\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterp_win\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterp_delta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\numba\\np\\ufunc\\gufunc.py:192\u001b[0m, in \u001b[0;36mGUFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(sig)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_ufunc()\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mufunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ms,train_labels = preprocess_dataset(train_files)\n",
    "test_ms,test_labels = preprocess_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nbc = GaussianNB()\n",
    "nbc.fit(train_ms,train_labels)\n",
    "test_pred = nbc.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5246666666666666 0.5603083326312298 0.5275950401581319 0.523091491691517\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = [{\"n_neighbors\": [i for i in range(1, 50)]}]\n",
    "\n",
    "knn_reg = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_reg, param_grid, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(train_ms,train_labels)\n",
    "p_knn = grid_search.best_params_\n",
    "p_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_clf = KNeighborsClassifier(n_neighbors=p_knn['n_neighbors'])\n",
    "kNN_clf.fit(train_ms,train_labels)\n",
    "test_pred = kNN_clf.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9615555555555556 0.9618582496696565 0.9617385019484525 0.961709563659569\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 396 candidates, totalling 792 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 7.0, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "param_grid = [{\"C\": [i for i in np.arange(0.1, 10, 0.1)],\n",
    "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "svc = SVC()\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=2, verbose=3, n_jobs=2)\n",
    "\n",
    "grid_search.fit(train_ms,train_labels)\n",
    "p_svc = grid_search.best_params_\n",
    "p_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(C=p_svc['C'], kernel=p_svc['kernel'])\n",
    "svc_clf.fit(train_ms,train_labels)\n",
    "test_pred = svc_clf.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827777777777778 0.9828218063508887 0.9828538093646163 0.9828169433344973\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 40 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "8 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n",
      "ValueError: nu <= 0 or nu > 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.93214286 0.92714286 0.913      0.886      0.84271429\n",
      " 0.79228571 0.72414286 0.64757143 0.54242857        nan 0.93871429\n",
      " 0.93242857 0.91771429 0.88671429 0.84657143 0.785      0.70828571\n",
      " 0.62157143 0.51314286        nan 0.94471429 0.93942857 0.92928571\n",
      " 0.904      0.87085714 0.82357143 0.77214286 0.70871429 0.63014286\n",
      "        nan 0.13228571 0.12328571 0.14871429 0.10042857 0.09057143\n",
      " 0.12557143 0.11885714 0.12442857 0.10885714]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'nu': 0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "param_grid = [{\"nu\": [i for i in np.arange(0, 1, 0.1)],\n",
    "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "nu_svc = NuSVC()\n",
    "grid_search = GridSearchCV(nu_svc, param_grid, cv=2, verbose=3, n_jobs=4)\n",
    "\n",
    "grid_search.fit(train_ms,train_labels)\n",
    "p_nu_svc = grid_search.best_params_\n",
    "p_nu_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_svc_clf = NuSVC(kernel=p_nu_svc['kernel'], nu=p_nu_svc['nu'])\n",
    "nu_svc_clf.fit(train_ms,train_labels)\n",
    "test_pred = nu_svc_clf.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9781111111111112 0.9782100283875357 0.9781793861673531 0.9781536982578132\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 152 candidates, totalling 304 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "38 fits failed out of a total of 304.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "38 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.91814286 0.92471429 0.92471429 0.90657143 0.91914286\n",
      " 0.92471429 0.92471429        nan 0.91757143 0.92471429 0.92471429\n",
      " 0.906      0.92       0.92471429 0.92471429        nan 0.91814286\n",
      " 0.92471429 0.92471429 0.90628571 0.91985714 0.92471429 0.92471429\n",
      "        nan 0.91771429 0.92471429 0.92471429 0.90557143 0.91885714\n",
      " 0.92471429 0.92471429        nan 0.91757143 0.92471429 0.92471429\n",
      " 0.90642857 0.91857143 0.92471429 0.92471429        nan 0.91757143\n",
      " 0.92471429 0.92471429 0.90685714 0.91928571 0.92471429 0.92471429\n",
      "        nan 0.91742857 0.92471429 0.92471429 0.90714286 0.91842857\n",
      " 0.92471429 0.92471429        nan 0.91742857 0.92471429 0.92471429\n",
      " 0.90628571 0.91857143 0.92471429 0.92471429        nan 0.91714286\n",
      " 0.92471429 0.92471429 0.90828571 0.91814286 0.92471429 0.92471429\n",
      "        nan 0.91742857 0.92471429 0.92471429 0.90871429 0.91857143\n",
      " 0.92471429 0.92471429        nan 0.917      0.92471429 0.92471429\n",
      " 0.91       0.91785714 0.92471429 0.92457143        nan 0.91757143\n",
      " 0.92471429 0.92471429 0.91042857 0.918      0.92471429 0.92471429\n",
      "        nan 0.91728571 0.92471429 0.92471429 0.909      0.91771429\n",
      " 0.92471429 0.92471429        nan 0.91728571 0.92471429 0.92471429\n",
      " 0.91057143 0.91857143 0.92471429 0.92471429        nan 0.91757143\n",
      " 0.92471429 0.92471429 0.91085714 0.91842857 0.92471429 0.92471429\n",
      "        nan 0.91714286 0.92471429 0.92471429 0.91128571 0.91857143\n",
      " 0.92471429 0.92471429        nan 0.91728571 0.92471429 0.92471429\n",
      " 0.91114286 0.91842857 0.92471429 0.92471429        nan 0.91771429\n",
      " 0.92471429 0.92471429 0.91157143 0.91842857 0.92471429 0.92471429\n",
      "        nan 0.91685714 0.92471429 0.92471429 0.91214286 0.91785714\n",
      " 0.92471429 0.92471429]\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'dual': True, 'multi_class': 'crammer_singer', 'penalty': 'l1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid = [{\"C\": [i for i in np.arange(0.5, 10, 0.5)],\n",
    "              \"penalty\": ['l1', 'l2'],\n",
    "              \"dual\": [True, False],\n",
    "              \"multi_class\": ['ovr', 'crammer_singer']}]\n",
    "\n",
    "lin_svc = LinearSVC()\n",
    "grid_search = GridSearchCV(lin_svc, param_grid, cv=2, verbose=3, n_jobs=4)\n",
    "\n",
    "grid_search.fit(train_ms,train_labels)\n",
    "p_lin_svc = grid_search.best_params_\n",
    "p_lin_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lin_svc_clf = LinearSVC(C=p_lin_svc['C'], dual=p_lin_svc['dual'], \n",
    "                        multi_class=p_lin_svc['multi_class'], penalty=p_lin_svc['penalty'])\n",
    "lin_svc_clf.fit(train_ms,train_labels)\n",
    "test_pred = lin_svc_clf.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9592222222222222 0.959332255263876 0.9593479165894104 0.9593073708577251\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1600 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 46, 'n_estimators': 420}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [{\"n_estimators\": [i for i in np.arange(100, 500, 10)], \"max_depth\": [i for i in range(10, 50)]}]\n",
    "\n",
    "rfc_reg = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rfc_reg, param_grid, cv=2, n_jobs=4, verbose=3)\n",
    "\n",
    "grid_search.fit(train_ms,train_labels)\n",
    "p_rfc = grid_search.best_params_\n",
    "p_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_clf = RandomForestClassifier(max_depth=p_rfc['max_depth'], n_estimators=p_rfc['n_estimators'])\n",
    "rfc_clf.fit(train_ms,train_labels)\n",
    "test_pred = rfc_clf.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9336666666666666 0.9338839242456158 0.9339832706766187 0.9337511978541275\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 13200 candidates, totalling 26400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "13200 fits failed out of a total of 26400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6600 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.58614286 0.59314286 0.59185714 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 45,\n",
       " 'max_leaf_nodes': 30,\n",
       " 'n_estimators': 450,\n",
       " 'oob_score': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "param_grid = [{\"n_estimators\": [i for i in np.arange(300, 500, 10)], \n",
    "               \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "               \"max_depth\": [i for i in np.arange(30, 55, 5)],\n",
    "              \"max_leaf_nodes\": [i for i in np.arange(10, 32, 2)],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"oob_score\": [True, False]}]\n",
    "\n",
    "etc_reg = ExtraTreesClassifier()\n",
    "grid_search = GridSearchCV(etc_reg, param_grid, cv=2, n_jobs=4, verbose=3)\n",
    "\n",
    "grid_search.fit(train_ms,train_labels)\n",
    "p_etc = grid_search.best_params_\n",
    "p_etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_clf = ExtraTreesClassifier(max_depth=p_etc['max_depth'], n_estimators=p_etc['n_estimators'], \n",
    "                               criterion=p_etc['criterion'], max_leaf_nodes=p_etc['max_leaf_nodes'], \n",
    "                               bootstrap=p_etc['bootstrap'], oob_score=p_etc['oob_score'])\n",
    "etc_clf.fit(train_ms,train_labels)\n",
    "test_pred = etc_clf.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6897777777777778 0.7141300286305049 0.6930224757393411 0.6879189084097986\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 165 candidates, totalling 330 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "110 fits failed out of a total of 330.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.31128571 0.32128571 0.33457143 0.33985714 0.35214286 0.36342857\n",
      " 0.38142857 0.38857143 0.39571429 0.406      0.41328571 0.31128571\n",
      " 0.32128571 0.33457143 0.33985714 0.35214286 0.36342857 0.38142857\n",
      " 0.38857143 0.39571429 0.406      0.41328571 0.31128571 0.32128571\n",
      " 0.33457143 0.33985714 0.35214286 0.36342857 0.38142857 0.38857143\n",
      " 0.39571429 0.406      0.41328571 0.31128571 0.32128571 0.33457143\n",
      " 0.33985714 0.35214286 0.36342857 0.38142857 0.38857143 0.39571429\n",
      " 0.406      0.41328571 0.31128571 0.32128571 0.33457143 0.33985714\n",
      " 0.35214286 0.36342857 0.38142857 0.38857143 0.39571429 0.406\n",
      " 0.41328571 0.30157143 0.32357143 0.34214286 0.35685714 0.36785714\n",
      " 0.37014286 0.37928571 0.386      0.38842857 0.39871429 0.40528571\n",
      " 0.30157143 0.32357143 0.34214286 0.35685714 0.36785714 0.37014286\n",
      " 0.37928571 0.386      0.38842857 0.39871429 0.40528571 0.30157143\n",
      " 0.32357143 0.34214286 0.35685714 0.36785714 0.37014286 0.37928571\n",
      " 0.386      0.38842857 0.39871429 0.40528571 0.30157143 0.32357143\n",
      " 0.34214286 0.35685714 0.36785714 0.37014286 0.37928571 0.386\n",
      " 0.38842857 0.39871429 0.40528571 0.30157143 0.32357143 0.34214286\n",
      " 0.35685714 0.36785714 0.37014286 0.37928571 0.386      0.38842857\n",
      " 0.39871429 0.40528571        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 30, 'max_leaf_nodes': 30}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = [{\"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "               \"max_depth\": [i for i in np.arange(30, 55, 5)],\n",
    "              \"max_leaf_nodes\": [i for i in np.arange(10, 32, 2)]}]\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(dtc, param_grid, cv=2, n_jobs=4, verbose=3)\n",
    "\n",
    "grid_search.fit(train_ms,train_labels)\n",
    "p_dtc = grid_search.best_params_\n",
    "p_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_clf = DecisionTreeClassifier(max_depth=p_dtc['max_depth'], max_leaf_nodes=p_dtc['max_leaf_nodes'], \n",
    "                                 criterion=p_dtc['criterion'])\n",
    "dtc_clf.fit(train_ms,train_labels)\n",
    "test_pred = dtc_clf.predict(test_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4172222222222222 0.4513284994340073 0.4175026596678477 0.42658331033426167\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, test_pred),\n",
    "precision_score(test_labels, test_pred, average='macro'),\n",
    "recall_score(test_labels, test_pred, average='macro'),\n",
    "f1_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ms_lstm(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    ms = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=512)\n",
    "    ms = np.resize(ms, input_shape)\n",
    "    \n",
    "    ms = np.log(ms + 1e-9)\n",
    "    ms = librosa.util.normalize(ms)\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_lstm(files):\n",
    "    output_labels = np.array([get_label(file) for file in files])\n",
    "    output_ms = np.array([get_ms_lstm(file) for file in files])\n",
    "    return output_ms, output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ms2,train_labels2 = preprocess_dataset_lstm(train_files)\n",
    "test_ms2,test_labels2 = preprocess_dataset_lstm(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(units=256, dropout=0.1, \n",
    "                            return_sequences=True, \n",
    "                            input_shape=(128,44)))\n",
    "model.add(keras.layers.LSTM(units=128,  dropout=0.1, \n",
    "                            return_sequences=False))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9, decay=1e-2/epoch),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "329/329 [==============================] - 220s 657ms/step - loss: 2.0779 - accuracy: 0.2364 - val_loss: 2.0106 - val_accuracy: 0.2218\n",
      "Epoch 2/25\n",
      "329/329 [==============================] - 218s 664ms/step - loss: 1.5899 - accuracy: 0.3936 - val_loss: 1.5931 - val_accuracy: 0.3931\n",
      "Epoch 3/25\n",
      "329/329 [==============================] - 229s 696ms/step - loss: 1.2502 - accuracy: 0.5282 - val_loss: 1.3189 - val_accuracy: 0.5004\n",
      "Epoch 4/25\n",
      "329/329 [==============================] - 231s 703ms/step - loss: 0.9584 - accuracy: 0.6461 - val_loss: 0.9508 - val_accuracy: 0.6497\n",
      "Epoch 5/25\n",
      "329/329 [==============================] - 233s 707ms/step - loss: 0.8109 - accuracy: 0.6964 - val_loss: 1.1405 - val_accuracy: 0.6071\n",
      "Epoch 6/25\n",
      "329/329 [==============================] - 234s 713ms/step - loss: 0.6941 - accuracy: 0.7441 - val_loss: 0.8902 - val_accuracy: 0.6891\n",
      "Epoch 7/25\n",
      "329/329 [==============================] - 236s 717ms/step - loss: 0.5854 - accuracy: 0.7807 - val_loss: 0.7754 - val_accuracy: 0.7343\n",
      "Epoch 8/25\n",
      "329/329 [==============================] - 236s 718ms/step - loss: 0.5147 - accuracy: 0.8126 - val_loss: 0.5626 - val_accuracy: 0.7853\n",
      "Epoch 9/25\n",
      "329/329 [==============================] - 235s 715ms/step - loss: 0.4721 - accuracy: 0.8255 - val_loss: 0.4351 - val_accuracy: 0.8331\n",
      "Epoch 10/25\n",
      "329/329 [==============================] - 235s 715ms/step - loss: 0.4440 - accuracy: 0.8332 - val_loss: 0.5331 - val_accuracy: 0.8170\n",
      "Epoch 11/25\n",
      "329/329 [==============================] - 238s 723ms/step - loss: 0.4024 - accuracy: 0.8499 - val_loss: 0.3440 - val_accuracy: 0.8722\n",
      "Epoch 12/25\n",
      "329/329 [==============================] - 238s 724ms/step - loss: 0.3757 - accuracy: 0.8611 - val_loss: 0.3031 - val_accuracy: 0.8870\n",
      "Epoch 13/25\n",
      "329/329 [==============================] - 238s 723ms/step - loss: 0.3645 - accuracy: 0.8653 - val_loss: 0.3041 - val_accuracy: 0.8892\n",
      "Epoch 14/25\n",
      "329/329 [==============================] - 239s 726ms/step - loss: 0.3319 - accuracy: 0.8747 - val_loss: 0.2994 - val_accuracy: 0.8890\n",
      "Epoch 15/25\n",
      "329/329 [==============================] - 240s 730ms/step - loss: 0.3245 - accuracy: 0.8797 - val_loss: 0.3422 - val_accuracy: 0.8741\n",
      "Epoch 16/25\n",
      "329/329 [==============================] - 241s 733ms/step - loss: 0.2991 - accuracy: 0.8910 - val_loss: 0.3476 - val_accuracy: 0.8778\n",
      "Epoch 17/25\n",
      "329/329 [==============================] - 242s 737ms/step - loss: 0.2832 - accuracy: 0.8944 - val_loss: 0.2951 - val_accuracy: 0.8957\n",
      "Epoch 18/25\n",
      "329/329 [==============================] - 242s 735ms/step - loss: 0.2816 - accuracy: 0.8971 - val_loss: 0.2110 - val_accuracy: 0.9250\n",
      "Epoch 19/25\n",
      "329/329 [==============================] - 242s 734ms/step - loss: 0.2616 - accuracy: 0.9060 - val_loss: 0.2423 - val_accuracy: 0.9129\n",
      "Epoch 20/25\n",
      "329/329 [==============================] - 242s 736ms/step - loss: 0.2515 - accuracy: 0.9094 - val_loss: 0.2369 - val_accuracy: 0.9151\n",
      "Epoch 21/25\n",
      "329/329 [==============================] - 242s 737ms/step - loss: 0.2431 - accuracy: 0.9109 - val_loss: 0.2140 - val_accuracy: 0.9233\n",
      "Epoch 22/25\n",
      "329/329 [==============================] - 243s 737ms/step - loss: 0.2348 - accuracy: 0.9149 - val_loss: 0.3053 - val_accuracy: 0.8904\n",
      "Epoch 23/25\n",
      "329/329 [==============================] - 244s 741ms/step - loss: 0.2245 - accuracy: 0.9180 - val_loss: 0.1860 - val_accuracy: 0.9340\n",
      "Epoch 24/25\n",
      "329/329 [==============================] - 244s 742ms/step - loss: 0.2200 - accuracy: 0.9215 - val_loss: 0.2702 - val_accuracy: 0.8987\n",
      "Epoch 25/25\n",
      "329/329 [==============================] - 244s 741ms/step - loss: 0.2110 - accuracy: 0.9235 - val_loss: 0.1828 - val_accuracy: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c10078ee80>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ms2,train_labels2, \n",
    "    validation_data=(test_ms2,test_labels2), \n",
    "    batch_size=64, \n",
    "    epochs=epoch,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 40s 139ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_ms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = [np.argmax(x) for x in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934 0.9360419003610723 0.9344363414504109 0.9338980411266476\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels2, test_pred2),\n",
    "precision_score(test_labels2, test_pred2, average='macro'),\n",
    "recall_score(test_labels2, test_pred2, average='macro'),\n",
    "f1_score(test_labels2, test_pred2, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
